<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>zisedeqing</title>
  
  
  <link href="https://zisedeqing.github.io/atom.xml" rel="self"/>
  
  <link href="https://zisedeqing.github.io/"/>
  <updated>2020-12-29T06:59:33.634Z</updated>
  <id>https://zisedeqing.github.io/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>64 bits GXID</title>
    <link href="https://zisedeqing.github.io/2020/12/29/64-bits-GXID/"/>
    <id>https://zisedeqing.github.io/2020/12/29/64-bits-GXID/</id>
    <published>2020-12-29T03:31:27.000Z</published>
    <updated>2020-12-29T06:59:33.634Z</updated>
    
    <content type="html"><![CDATA[<p>社区的MR:<a href="https://github.com/greenplum-db/gpdb/pull/10910">https://github.com/greenplum-db/gpdb/pull/10910</a><br>distributed snapshot膨胀：使用相对值，依然32位<br>dlog膨胀：去掉timestamp，报错和之前一样<br>ShmemVariableCache-&gt;nextGxid在异常宕机、主备切换时的维护：<br>作用于ShmemVariableCache-&gt;nextXid一样。</p><a id="more"></a><p>2种方案：</p><ol><li>与oid类似，按批来处理，每批记一次xlog。社区认为这个代价太大了。</li><li>现在使用的方案<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Another solution (in this patch) is:</span><br><span class="line"></span><br><span class="line">Always update ShmemVariableCache-&gt;nextGxid in checkpoint and one phase</span><br><span class="line">commit&#x2F;prepare (during both commit and redo code)</span><br><span class="line"></span><br><span class="line">in dtx recovery, for the scenarios, it previously terminate all backends in</span><br><span class="line">such case, now it dispatches a udf to collect the max nextGxid on all segments</span><br><span class="line">and compare with ShmemVariableCache-&gt;nextGxid to get the max nextGxid.</span><br><span class="line">Need to write the code very carefully when handling those orphaned segment</span><br><span class="line">processes on segments.</span><br></pre></td></tr></table></figure>与xid类似，记录到xlog中，从xlog里面恢复到正确的值。<br>对于多master，这个需要做一些改动，因为gxid是在gtm上生成的。</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;社区的MR:&lt;a href=&quot;https://github.com/greenplum-db/gpdb/pull/10910&quot;&gt;https://github.com/greenplum-db/gpdb/pull/10910&lt;/a&gt;&lt;br&gt;distributed snapshot膨胀：使用相对值，依然32位&lt;br&gt;dlog膨胀：去掉timestamp，报错和之前一样&lt;br&gt;ShmemVariableCache-&amp;gt;nextGxid在异常宕机、主备切换时的维护：&lt;br&gt;作用于ShmemVariableCache-&amp;gt;nextXid一样。&lt;/p&gt;</summary>
    
    
    
    <category term="greenplum6.0" scheme="https://zisedeqing.github.io/categories/greenplum6-0/"/>
    
    <category term="transaction" scheme="https://zisedeqing.github.io/categories/greenplum6-0/transaction/"/>
    
    
    <category term="greenplum" scheme="https://zisedeqing.github.io/tags/greenplum/"/>
    
    <category term="gxid" scheme="https://zisedeqing.github.io/tags/gxid/"/>
    
    <category term="64位" scheme="https://zisedeqing.github.io/tags/64%E4%BD%8D/"/>
    
  </entry>
  
  <entry>
    <title>postgresql jdbc 走simple query protocol</title>
    <link href="https://zisedeqing.github.io/2020/12/29/postgresql-jdbc-%E8%B5%B0simple-query-protocol/"/>
    <id>https://zisedeqing.github.io/2020/12/29/postgresql-jdbc-%E8%B5%B0simple-query-protocol/</id>
    <published>2020-12-29T01:56:00.000Z</published>
    <updated>2020-12-29T02:07:50.659Z</updated>
    
    <content type="html"><![CDATA[<p>默认情况下，jdbc的所有sql使用extended query protocol，不过pg的jdbc提供了使用simple query protocol方法。<br><strong>需要注意的是，使用simple query protocol后，jdbc的cursor功能将会失效，也就是无论setFetchSize设置为多大，jdbc都会一次把数据全部存到jdbc。不过resultset的滚动和update功能还是可以使用的。</strong></p><a id="more"></a><ul><li><input checked disabled type="checkbox"> <strong>connection级别</strong></li></ul><p>在链接字符串中添加preferQueryMode=simple参数，这样connection所有的sql执行使用的都是simple query protocol。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Class.forName(<span class="string">&quot;org.postgresql.Driver&quot;</span>);</span><br><span class="line"><span class="comment">// set preferQueryMode=simple</span></span><br><span class="line">Connection conn = DriverManager.getConnection(<span class="string">&quot;jdbc:postgresql://localhost:15432/postgres?preferQueryMode=simple&quot;</span>, <span class="string">&quot;postgres&quot;</span>, <span class="string">&quot;&quot;</span>);</span><br><span class="line">Statement stmt = conn.createStatement();</span><br><span class="line">ResultSet rs = stmt.executeQuery(<span class="string">&quot;select * from test8 where b = 1&quot;</span>);</span><br><span class="line"><span class="keyword">while</span> (rs.next()) &#123;</span><br><span class="line">ResultSetMetaData rsm = rs.getMetaData();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= rsm.getColumnCount(); i++) &#123;</span><br><span class="line">System.out.println(rsm.getColumnName(i) + <span class="string">&quot;:&quot;</span> + rs.getString(i));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><input checked disabled type="checkbox"> <strong>sql级别</strong></li></ul><p>如果只针对某些sql使用simple query protocol，标准jdbc接口是无法实现的，只能通过pg的jdbc接口实现</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Class.forName(<span class="string">&quot;org.postgresql.Driver&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// preferQueryMode 不能为simpe或者extended,可以为extendedForPrepared或者extendedCacheEverything</span></span><br><span class="line">Connection conn = DriverManager.getConnection(<span class="string">&quot;jdbc:postgresql://localhost:15432/postgres?preferQueryMode=extendedForPrepared&quot;</span>, <span class="string">&quot;postgres&quot;</span>, <span class="string">&quot;&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 强制转换标准Statement为PgStatement</span></span><br><span class="line">PgStatement pgStmt = (PgStatement)conn.createStatement();</span><br><span class="line"><span class="keyword">if</span> (pgStmt.executeWithFlags(<span class="string">&quot;select * from test8 where b = 2&quot;</span>, QueryExecutor.QUERY_EXECUTE_AS_SIMPLE)) &#123;</span><br><span class="line">  ResultSet rs = pgStmt.getResultSet();</span><br><span class="line">  <span class="keyword">while</span> (rs.next()) &#123;</span><br><span class="line">ResultSetMetaData rsm = rs.getMetaData();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= rsm.getColumnCount(); i++) &#123;</span><br><span class="line">System.out.println(rsm.getColumnName(i) + <span class="string">&quot;:&quot;</span> + rs.getString(i));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;默认情况下，jdbc的所有sql使用extended query protocol，不过pg的jdbc提供了使用simple query protocol方法。&lt;br&gt;&lt;strong&gt;需要注意的是，使用simple query protocol后，jdbc的cursor功能将会失效，也就是无论setFetchSize设置为多大，jdbc都会一次把数据全部存到jdbc。不过resultset的滚动和update功能还是可以使用的。&lt;/strong&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="postgresql" scheme="https://zisedeqing.github.io/categories/postgresql/"/>
    
    <category term="jdbc" scheme="https://zisedeqing.github.io/categories/postgresql/jdbc/"/>
    
    
    <category term="jdbc" scheme="https://zisedeqing.github.io/tags/jdbc/"/>
    
    <category term="postgresql" scheme="https://zisedeqing.github.io/tags/postgresql/"/>
    
    <category term="simple" scheme="https://zisedeqing.github.io/tags/simple/"/>
    
  </entry>
  
  <entry>
    <title>Greenplum jdbc qps 问题</title>
    <link href="https://zisedeqing.github.io/2020/12/29/Greenplum-jdbc-qps-%E9%97%AE%E9%A2%98/"/>
    <id>https://zisedeqing.github.io/2020/12/29/Greenplum-jdbc-qps-%E9%97%AE%E9%A2%98/</id>
    <published>2020-12-29T01:23:26.000Z</published>
    <updated>2020-12-29T02:07:53.161Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>目前的现象是使用psql 执行点查，qps比使用jdbc执行相同的sql 要好几倍。<br>在docker里面做了一下测试，下面是测试脚本：</p><a id="more"></a><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">pronum=4</span><br><span class="line">dbname=postgres</span><br><span class="line"></span><br><span class="line">wait_end()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">true</span></span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line"><span class="built_in">jobs</span></span><br><span class="line">        running=`<span class="built_in">jobs</span>|wc -l`</span><br><span class="line">        ret=$?</span><br><span class="line">        [ ! <span class="variable">$ret</span> -eq 0 ] &amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;check running process failed, error <span class="variable">$ret</span>&quot;</span> &amp;&amp; <span class="built_in">return</span> <span class="variable">$ret</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;running process <span class="variable">$running</span>&quot;</span></span><br><span class="line">        <span class="keyword">if</span> [ <span class="variable">$running</span> -le 0 ];<span class="keyword">then</span></span><br><span class="line">            <span class="built_in">return</span> 0</span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">        sleep 1</span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">start_tm=`date +%s%N`;</span><br><span class="line"><span class="keyword">for</span>((i=0;i&lt;pronum;i++))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    psql -d <span class="variable">$dbname</span> -f test.sql &amp;&gt;/dev/null &amp;</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;waiting job finish ...&quot;</span></span><br><span class="line">wait_end</span><br><span class="line">end_tm=`date +%s%N`;</span><br><span class="line">use_tm=`<span class="built_in">echo</span> <span class="variable">$end_tm</span> <span class="variable">$start_tm</span> | awk <span class="string">&#x27;&#123; print ($1 - $2) / 1000000000&#125;&#x27;</span>`</span><br><span class="line">qps=`<span class="built_in">echo</span> <span class="string">&quot;(<span class="variable">$pronum</span> * 1050) / <span class="variable">$use_tm</span>&quot;</span>|bc`</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;use time: <span class="variable">$use_tm</span> (s), qps: <span class="variable">$qps</span> (q/s)&quot;</span></span><br></pre></td></tr></table></figure><p>test.sql 里面是1000行SELECT * from test8 where b = 1000</p><p>jdbc程序：<a href="test2.tar.gz">test2.tar.gz</a><br>命令行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -cp .&#x2F;*:.&#x2F;test2-1.0-SNAPSHOT-jar-with-dependencies.jar MainEntry jdbc:postgresql:&#x2F;&#x2F;localhost:15432&#x2F;postgres postgres 111 &quot;select * from test8 where b &#x3D;1000&quot; 1000 4 true</span><br></pre></td></tr></table></figure><p><strong>测试结果：</strong><br>psql:<br>use time: 6.08536 (s), qps: 690 (q/s)<br>jdbc:<br>Total run time: 33209 ms<br>QPS Tester: QPS = [120.44927579872925] querys/s</p><h1 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h1><p>修改log级别为DEBUG5(set log_min_messages=DEBUG5)，输出更详细的log，比较psql与jdbc执行SELECT * from test8 where b = 1000的差异，对比发现使用jdbc时，有如下log：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DEBUG5:  CdbDoCommand for command &#x3D; &#39;set gp_write_shared_snapshot&#x3D;true&#39;, needTwoPhase &#x3D; true</span><br><span class="line">DEBUG5:  dtmPreCommand going distributed (all gangs) for gid &#x3D; 1554712434-0000012220 (CdbDoCommand, detail &#x3D; &#39;set gp_write_shared_snapshot&#x3D;true&#39;)</span><br><span class="line">DEBUG3:  cdbdisp_dispatchCommand: set gp_write_shared_snapshot&#x3D;true (needTwoPhase &#x3D; true)</span><br><span class="line">DEBUG5:  mppTxnOptions DefaultXactIsoLevel &#x3D; READ COMMITTED, DefaultXactReadOnly &#x3D; false, XactIsoLevel &#x3D; READ COMMITTED, XactReadOnly &#x3D; false.</span><br><span class="line">DEBUG5:  mppTxnOptions txnOptions &#x3D; 0x3, needTwoPhase &#x3D; true, explicitBegin &#x3D; false, isoLevel &#x3D; READ COMMITTED, readOnly &#x3D; false.</span><br></pre></td></tr></table></figure><p>QD 在执行查询之前会给每个segment发送set gp_write_shared_snapshot=true，并且启动two phase commit。<br>代码如下：<br><img src="/2020/12/29/Greenplum-jdbc-qps-%E9%97%AE%E9%A2%98/verify_shared_snapshot_ready.png" alt="verify_shared_snapshot_ready"><br><img src="/2020/12/29/Greenplum-jdbc-qps-%E9%97%AE%E9%A2%98/verify_shared_snapshot_ready.png" alt="verify_shared_snapshot_ready"></p><p>QD对应extended query，在ExecutorStart和cdbdisp_dispatchPlan时，会执行verify_shared_snapshot_ready，该函数会dispatch set gp_write_shared_snapshot=true到每个segment，并使用两阶段提交，拖慢整个执行性能。</p><ul><li><p><strong>问题1：shared snapshot是干什么用的？</strong><br>参考: <a href="/2020/12/28/Greenplum-shared-snapshot/index.html">Greenplum shared snapshot</a></p></li><li><p><strong>问题2：verify_shared_snapshot_ready的作用是什么？</strong></p></li></ul><p>根据注释看，该函数的主要作用是在segment上启动一个writer gang，并且生成shared snapshot。</p><ul><li><input checked disabled type="checkbox"> <strong>问题3：为什么extended query 会比simple query多走这一步？</strong></li></ul><p>根据代码和注释了解，extended query在执行的时候，是没有writer gang的，所有的执行操作都是在reader gang中，但是reader gang也需要snapshot，所以需要执行此操作。</p><ul><li><input checked disabled type="checkbox"> <strong>问题4：问什么extended query没有writer gang？</strong></li></ul><p><img src="/2020/12/29/Greenplum-jdbc-qps-%E9%97%AE%E9%A2%98/assignGangs.png" alt="image.png"><br>从上面的代码可以看到，在assignGangs时，如果是extended query，则跳过writer gang的分配，只分配reader gang。<br><strong>对于cursor，同一个session可以同时执行多个cursor，由于writer gang只能有一个，所以所有的cursor只能在reader gang中执行，并且cursor是不会修改数据的，所以assignGangs没有分配writer gang。</strong></p><p>例子1 psql：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">postgres&#x3D;# BEGIN ;</span><br><span class="line">BEGIN</span><br><span class="line">postgres&#x3D;# DECLARE c1 CURSOR for select a from test8 where b &#x3D;10;</span><br><span class="line">DECLARE CURSOR</span><br><span class="line">postgres&#x3D;# DECLARE c2 CURSOR for select a from test8 where b &#x3D;11;</span><br><span class="line">DECLARE CURSOR</span><br><span class="line">postgres&#x3D;# FETCH c1;</span><br><span class="line"> a</span><br><span class="line">----</span><br><span class="line"> 10</span><br><span class="line">(1 row)</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# FETCH c2;</span><br><span class="line"> a</span><br><span class="line">----</span><br><span class="line"> 11</span><br><span class="line">(1 row)</span><br><span class="line"></span><br><span class="line">postgres&#x3D;# CLOSE c1;</span><br><span class="line">CLOSE CURSOR</span><br><span class="line">postgres&#x3D;# close c2;</span><br><span class="line">CLOSE CURSOR</span><br><span class="line">postgres&#x3D;#</span><br></pre></td></tr></table></figure><p>例子2 jdbc:<br>关于jdbc开启cursor的文档：<a href="https://jdbc.postgresql.org/documentation/94/query.html#query-with-cursor">https://jdbc.postgresql.org/documentation/94/query.html#query-with-cursor</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> Connection conn = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">static</span> Statement stmt = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> ClassNotFoundException, SQLException </span>&#123;</span><br><span class="line">        Class.forName(<span class="string">&quot;org.postgresql.Driver&quot;</span>);</span><br><span class="line">        conn = DriverManager.getConnection(<span class="string">&quot;jdbc:postgresql://localhost:15432/postgres&quot;</span>, <span class="string">&quot;postgres&quot;</span>, <span class="string">&quot;&quot;</span>);</span><br><span class="line">        conn.setAutoCommit(<span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">        Statement st1 = conn.createStatement();</span><br><span class="line">        Statement st2 = conn.createStatement();</span><br><span class="line">        st1.setFetchSize(<span class="number">1</span>);</span><br><span class="line">        st2.setFetchSize(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        ResultSet rs1 = st1.executeQuery(<span class="string">&quot;select a from test8 where b = 1&quot;</span>);</span><br><span class="line">        ResultSet rs2 = st2.executeQuery(<span class="string">&quot;select b from test8 where b = 11&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (rs1.next()) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;fetch rs1: &quot;</span> + rs1.getString(<span class="number">1</span>));</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (rs2.next()) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;fetch rs2: &quot;</span> + rs2.getString(<span class="number">1</span>));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (rs1.next()) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;fetch rs1: &quot;</span> + rs1.getString(<span class="number">1</span>));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (rs2.next()) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;fetch rs2: &quot;</span> + rs2.getString(<span class="number">1</span>));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        rs1.close();</span><br><span class="line">        rs2.close();</span><br><span class="line"></span><br><span class="line">        st1.close();</span><br><span class="line">        st2.close();</span><br><span class="line">        conn.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><input checked disabled type="checkbox"> <strong>问题4：为什么对于extended query，shared snapshot需要dump到file？</strong></li></ul><p>参考: <a href="/2020/12/28/Greenplum-shared-snapshot/index.html">Greenplum shared snapshot</a></p><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><p>有两种解决方式：</p><ul><li><p><strong>业务修改jdbc，让jdbc走simple query protocol</strong><br>参考: <a href="/2020/12/29/postgresql-jdbc-%E8%B5%B0simple-query-protocol/index.html">postgresql jdbc 走simple queryprotocol</a></p></li><li><p><strong>修改gp内存</strong></p></li></ul><p>针对cursor和extended query中的cursor，依然走原来的流程，对于非cursor的extended query走simple query 流程。<br><strong>如何区分cursor和extended query中的cursor？</strong><br>simple query: declare cursor/fetch<br>extended query: 如果是cursor bind时，会有portal name，否则portal name为空</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;目前的现象是使用psql 执行点查，qps比使用jdbc执行相同的sql 要好几倍。&lt;br&gt;在docker里面做了一下测试，下面是测试脚本：&lt;/p&gt;</summary>
    
    
    
    <category term="greenplum4.3" scheme="https://zisedeqing.github.io/categories/greenplum4-3/"/>
    
    <category term="performance" scheme="https://zisedeqing.github.io/categories/greenplum4-3/performance/"/>
    
    
    <category term="greenplum" scheme="https://zisedeqing.github.io/tags/greenplum/"/>
    
    <category term="jdbc" scheme="https://zisedeqing.github.io/tags/jdbc/"/>
    
    <category term="qps" scheme="https://zisedeqing.github.io/tags/qps/"/>
    
  </entry>
  
  <entry>
    <title>Greenplum Fts实现</title>
    <link href="https://zisedeqing.github.io/2020/12/28/Greenplum-Fts%E5%AE%9E%E7%8E%B0/"/>
    <id>https://zisedeqing.github.io/2020/12/28/Greenplum-Fts%E5%AE%9E%E7%8E%B0/</id>
    <published>2020-12-28T13:47:20.000Z</published>
    <updated>2020-12-29T03:22:31.723Z</updated>
    
    <content type="html"><![CDATA[<p>Greenplum 总共存在2个角色，每个角色有分别实现了standby，分别是：master和master的standby， primary segment和mirror segment。数据库的fault tolerance由fault tolerance server（简称FTS）来处理。<br>FTS主要监控和控制segment节点的状态，以及发生异常时进行切换，FTS并不监控standby的状态，目前的实现是由管控控制。<br>    FTS 由2类进程组成：ftsprobe 进程和 fts handle message 进程，ftsprobe 进程在master上，定期给segment发送探活消息， fts handle message 进程是segment上处理ftsprobe 进程探活消息的，改进程不是守护进程，处理完一次探活后，即退出。</p><a id="more"></a><p><img src="/2020/12/28/Greenplum-Fts%E5%AE%9E%E7%8E%B0/fts.png" alt="fts"><br>如上图所示，fts probe 定期发送探活信息给primary segment， primary segment收到探活信息，并从wal sender 获取mirror segment状态，然后回复给fts probe进程。backend与fts probe进程也有交互，fts probe更新节点状态后，通过ftsProbeInfo-&gt;status_version, backend可以感知到节点状态的变化。而backend在发现有些节点连不上时，也可以通过FtsNotifyProber来通知fts 探测节点是否正常。</p><h1 id="fts-probe"><a href="#fts-probe" class="headerlink" title="fts probe"></a>fts probe</h1><h2 id="fts-loop"><a href="#fts-loop" class="headerlink" title="fts loop"></a>fts loop</h2><p>fts probe 主函数FtsLoop，流程如下：<br><img src="/2020/12/28/Greenplum-Fts%E5%AE%9E%E7%8E%B0/FtsLoop.png" alt="FtsLoop"></p><ol><li><p>ftsProbeInfo-&gt;start_count和ftsProbeInfo-&gt;done_count给FtsNotifyProber中使用的。用于等待触发的探测结束。</p></li><li><p>ftsprobe每次探测开始时都会从新从gp_segment_configuration读取节点信息，探测完成后，在销毁。这么做的原因是有些脚本（如gpaddmirrors）可能会改gp_segment_configuration，所以每次都要读取最新的节点信息。</p></li><li><p>每次探测时，如果有节点状态发生变化，则会把gp_segment_configuration的信息dump到gpsegconfig_dump文件，主要的原因是防止在事务外需要访问节点信息。比如在2pc的第二阶段，如果commit or abort失败，需要重试时，就需要读取gpsegconfig_dump文件。**<img src="/2020/12/28/Greenplum-Fts%E5%AE%9E%E7%8E%B0/gpsegconfig_dump.png" alt="gpsegconfig_dump">**</p></li><li><p>ftsProbeInfo-&gt;status_version 表示节点状态信息的版本，每次发生变化都会+1，主要作用是通知其他进程节点状态发生变化了，需要重新更新节点状态，比如主备发生了切换等。ftsProbeInfo-&gt;status_version只会在ftsprobe 进程修改，其他进程都是只读，没有加ftsProbeInfo-&gt;lock。</p></li><li><p>FtsProbeInfo结构信息如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">FtsProbeInfo</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="comment">/* 节点状态信息的版本，每次如果有节点状态信息发生改变，则+1*/</span></span><br><span class="line"><span class="keyword">volatile</span> uint8status_version;</span><br><span class="line">    <span class="comment">/* 记录节点是否down，用于快速判断节点是否活着 */</span></span><br><span class="line"><span class="keyword">volatile</span> uint8status[FTS_MAX_DBS];</span><br><span class="line">    <span class="comment">/* 锁，控制除status之外的field的修改*/</span></span><br><span class="line"><span class="keyword">volatile</span> <span class="keyword">slock_t</span>lock;</span><br><span class="line">    <span class="comment">/* </span></span><br><span class="line"><span class="comment">     * start_count每次探测开始时+1, done_count每次探测与start_count相同</span></span><br><span class="line"><span class="comment">     * 这两个值主要在FtsNotifyProber中使用，用来判断探测是否结束。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"><span class="keyword">volatile</span> int32start_count;</span><br><span class="line"><span class="keyword">volatile</span> int32done_count;</span><br><span class="line">&#125; FtsProbeInfo;</span><br></pre></td></tr></table></figure><h2 id="FtsWalRepMessageSegments"><a href="#FtsWalRepMessageSegments" class="headerlink" title="FtsWalRepMessageSegments"></a>FtsWalRepMessageSegments</h2><p>master 发送探测消息，处理探测结果，并完成主备切换，流程如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">FtsWalRepInitProbeContext</span><br><span class="line">InitPollFds</span><br><span class="line"><span class="keyword">while</span> (!allDone(&amp;context) &amp;&amp; FtsIsActive())</span><br><span class="line">&#123;</span><br><span class="line">    ftsConnect(&amp;context);</span><br><span class="line">    ftsPoll(&amp;context);</span><br><span class="line">    ftsSend(&amp;context);</span><br><span class="line">    ftsReceive(&amp;context);</span><br><span class="line">    processRetry(&amp;context);</span><br><span class="line">    is_updated |= processResponse(&amp;context);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!FtsIsActive())</span><br><span class="line">释放连接和资源</span><br><span class="line">resetMarkPrimaryDead</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">int</span> num_pairs; <span class="comment">/* number of primary-mirror pairs FTS wants to probe */</span></span><br><span class="line">fts_segment_info *perSegInfos;</span><br><span class="line">&#125; fts_context;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">CdbComponentDatabaseInfo *primary_cdbinfo;</span><br><span class="line">CdbComponentDatabaseInfo *mirror_cdbinfo;</span><br><span class="line">fts_result result;</span><br><span class="line">FtsMessageState state;</span><br><span class="line"><span class="keyword">short</span> poll_events;</span><br><span class="line"><span class="keyword">short</span> poll_revents;</span><br><span class="line">int16 fd_index;               <span class="comment">/* index into PollFds array */</span></span><br><span class="line"><span class="keyword">pg_time_t</span> startTime;          <span class="comment">/* probe start timestamp */</span></span><br><span class="line"><span class="keyword">pg_time_t</span> retryStartTime;     <span class="comment">/* time at which next retry attempt can start */</span></span><br><span class="line">int16 probe_errno;            <span class="comment">/* saved errno from the latest system call */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">pg_conn</span> *<span class="title">conn</span>;</span>         <span class="comment">/* libpq connection object */</span></span><br><span class="line"><span class="keyword">int</span> retry_count;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* recover mode */</span></span><br><span class="line">XLogRecPtr xlogrecptr;</span><br><span class="line"><span class="keyword">bool</span> recovery_making_progress;</span><br><span class="line">&#125; fts_segment_info;</span><br></pre></td></tr></table></figure><p>fts context 记录本次探测的所有相关信息，主要记录在fts_segment_info， 每个对segment对应一个fts_segment_info，状态信息主要记录在primary_cdbinfo和mirror_cdbinfo里面，其他的字段都是用来控制探测，已经异常处理的。</p><h2 id="fts-探测过程"><a href="#fts-探测过程" class="headerlink" title="fts 探测过程"></a>fts 探测过程</h2><p>fts的探测过程是通过状态机控制的，根据不同的状态，进行相应的处理，状态机的转换主要在FtsWalRepMessageSegments函数内，状态机是按segment为单位的，每个segment使用单独状态机，互不影响，状态转换如下图所示：<br><img src="/2020/12/28/Greenplum-Fts%E5%AE%9E%E7%8E%B0/fts-probe-state-machine.png" alt="fts state machine"></p></li><li><p>FTS_PROBE_SEGMENT为起始状态，每次探测开始所有segment都出于改状态</p></li><li><p>FTS_PROBE_SUCCESS 分为下面几种情况：</p><ol><li>mirror 探测失败：如果要求重试(由参数gp_fts_mark_mirror_down_grace_period控制)，则忽略本次探测结果，重新探测；否则标记mirror down，并把状态改为FTS_SYNCREP_OFF_SEGMENT，通知primary 关闭同步复制。</li><li>primary和mirror同步状态发送改变: 同步状态从sync –&gt; not sync 或者not sync –&gt;sync</li><li>探测到mirror: 探测信息发送到mirror上了。正常情况下探测消息只会发给primary，这种情况一般是之前已经做完主备切换，但是mirror还没有完成切换。此时把状态改成FTS_PROMOTE_SEGMENT,再次通知mirror升主。</li></ol></li><li><p>FTS_PROBE_FAILED分为下面几种情况：</p><ol><li>需要重试(由参数gp_fts_probe_retries控制)，这修改状态为：FTS_PROBE_RETRY_WAIT</li><li>重试gp_fts_probe_retries次后，依然失败：<ol><li>primary 处于 recover mode，说明primary 正在恢复自身异常，过一会可能就会正常了，所有忽略本次探测结果。</li><li>切主。把处于sync状态的mirror 生成主。主要是更新catalog状态，然后把状态改成FTS_PROMOTE_SEGMENT</li><li>没有处于sync的mirror，无法自动恢复，需要人工介入：比如想办法重新恢复primary或者强制切换。</li></ol></li></ol></li><li><p>FTS_SYNCREP_OFF_SEGMENT：mirror down了，通知primary 关闭同步复制，避免查询hang住</p><ol><li>FTS_SYNCREP_OFF_SUCCESS：关闭成功，结束本次探测</li><li>FTS_SYNCREP_OFF_FAILED：关闭失败，重试gp_fts_probe_retries次。如果依然失败，则结束本次探测。</li></ol></li><li><p>FTS_PROMOTE_SEGMENT： primary down，通知mirror升级为primary</p><ol><li>FTS_PROMOTE_SUCCESS：升主成功，结束本次探测</li><li>FTS_PROMOTE_FAILED：升主失败，重试gp_fts_probe_retries次，如果依然失败，则结束本次探测。此时会影响数据库的使用，需要人工介入恢复。</li></ol></li><li><p>FTS_RESPONSE_PROCESSED：探测结束状态</p><h2 id="fts-消息格式"><a href="#fts-消息格式" class="headerlink" title="fts 消息格式"></a>fts 消息格式</h2><p>fts 探测消息格式固定，如下：<br>message type | primary_dbid | segment_contentid</p></li></ol><p>其中message type分别是：<br>FTS_PROBE_SEGMENT、FTS_SYNCREP_OFF_SEGMENT、FTS_PROMOTE_SEGMENT</p><h2 id="相关参数"><a href="#相关参数" class="headerlink" title="相关参数"></a>相关参数</h2><p>fts相关的几个参数，以及默认值：<br>gp_fts_probe_retries：3<br>gp_fts_probe_interval: 30s<br>gp_request_fts_probe_scan<br>gp_fts_probe_timeout: 60s<br>gp_fts_mark_mirror_down_grace_period:  mirror 失联多久才标记为down<br><strong>最大切换时间: 30 + 3 * (60 + 1) = 213s**<br>*<em>如果不发生timeout是: 30 + 3</em>1 = 33s</strong><br>**</p><h1 id="fts-message-handler"><a href="#fts-message-handler" class="headerlink" title="fts message handler"></a>fts message handler</h1><p>fts message handler 进程是在primary segment上处理master probe 消息的进程，该进程不是常驻进程，每次轮探测结束后，都会退出。<br>入口函数是HandleFtsMessage，主要处理master发送的3中消息，分别是：</p><ul><li><input checked disabled type="checkbox"> <strong>HandleFtsWalRepProbe</strong></li></ul><p>处理FTS_PROBE_SEGMENT消息，主要是通过wal sender查看mirror是否活着，并且检测primary 磁盘是否可读可写。</p><ol><li>mirror的处理：跟进WalSnd记录的信息，判断mirror是否活着以及是否与primary 同步</li><li>如果primary 与mirror失联了，则根据gp_fts_mark_mirror_down_grace_period的值，确定是否需要master标记为down或者重试。</li><li>如果mirror活着，并且处于非同步复制状态，则修改为同步复制</li></ol><ul><li><input checked disabled type="checkbox"> <strong>HandleFtsWalRepPromote</strong></li></ul><p>处理FTS_PROMOTE_SEGMENT消息，升级当前的mirror为primary：</p><ol><li>UnsetSyncStandbysDefined，修改为非同步复制，避免查询hang住</li><li>CreateReplicationSlotOnPromote，创建新的replication slots，避免xlog被回收。</li><li>SignalPromote，通知pm进程promote为主</li></ol><ul><li><input checked disabled type="checkbox"> <strong>HandleFtsWalRepSyncRepOff</strong></li></ul><p>处理FTS_SYNCREP_OFF_SEGMENT消息，关闭同步复制：</p><ol><li>UnsetSyncStandbysDefined</li><li>GetMirrorStatus</li></ol><h1 id="backend-与fts-probe的交互"><a href="#backend-与fts-probe的交互" class="headerlink" title="backend 与fts probe的交互"></a>backend 与fts probe的交互</h1><ul><li><input checked disabled type="checkbox"> <strong>交互的方式有哪些？</strong></li></ul><ol><li><p><strong>ftsProbeInfo-&gt;status_version</strong>: fts在每次改过segment信息后，会增加ftsProbeInfo-&gt;status_version，backend可以通过ftsProbeInfo-&gt;status_version比较自己缓存的版本是否过期，如果过期，则从新从catalog reload segment信息.</p></li><li><p>FtsNotifyProber: 其他进程可以调用该函数通知fts进行新一轮的探测</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">FtsNotifyProber</span><br><span class="line">readGpSegConfigFromFTSFiles</span><br><span class="line">cdbcomponent_updateCdbComponents</span><br><span class="line">cdbcomponent_getCdbComponents</span><br><span class="line">checkDispatchResult</span><br><span class="line">cdbgang_createGang_async</span><br><span class="line">gp_request_fts_probe_scan</span><br></pre></td></tr></table></figure><p>backend 在某些阶段发现节点通信异常时，会通知fts进行一次探测，看看节点是否正常。</p></li><li><p>SendPostmasterSignal(PMSIGNAL_WAKEN_FTS);</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SendPostmasterSignal(PMSIGNAL_WAKEN_FTS)</span><br><span class="line">cdbCopyEndInternal</span><br><span class="line">FtsNotifyProber</span><br><span class="line">sigusr1_handler</span><br><span class="line">PostmasterMain</span><br></pre></td></tr></table></figure><p>改方式与FtsNotifyProber的区别是，只是唤醒fts，做一次探测，但是backend并不会等待探测完成。</p></li></ol><ul><li><input checked disabled type="checkbox"> <strong>backend 什么时候能够收到fts 的信息变更？</strong></li></ul><ol><li>在事务开始时, StartTransaction会调用cdbcomponent_updateCdbComponents，比较版本是否过期，如果过期，则更新缓存。</li><li>doNotifyingCommitNotPrepared、doNotifyingCommitPrepared、retryAbortPrepared</li></ol><p>在上面3个事务处理函数中失败时，再次重试的时候，会从新更新缓存</p><ol start="3"><li>doNotifyingAbort、rollbackDtxTransaction</li></ol><p>在处理NO_PREPARED的事务时，如果失败，则会清除掉缓存cdb_component_dbs，后面再有操作时，就会更新缓存</p><ol start="4"><li>AtAbort_DispatcherState</li></ol><p>在writer gang出错时，会清除掉换成cdb_component_dbs，后面再有操作时，就会更新缓存</p><ol start="5"><li>assign_gp_role</li></ol><p>更新backend角色时，可能会更新缓存。</p><p>从上面可以看到，backend更新新的节点信息，主要在事务启动，或者事务结束时发生异常后，而在事务运行过程中，是不会更新节点信息的，这也是正确的，因为按现有的架构，在事务中间出错后，是无法继续做的，必须rollback。</p><ul><li><input checked disabled type="checkbox"> <strong>会不会出现双写的情况？</strong></li></ul><p>会不会出现有些事务在旧的primary上，而有些事务在新的primary上？只有提交的事务才会有问题，未提交的没有问题？出现双写的必要条件是master 认为primary down了，但是mirror还活着并且是sync状态。<br>考虑下面的场景：</p><ol><li><strong>网络抖动，导致fts认为primary挂掉了，但是实际还活着，则已经启动的事务还是会往旧primary 发送sql，而新的事务会在新的primary上。</strong></li></ol><p>场景构造：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">-- 先修改gp_fts_probe_interval&#x3D;20s，gp_fts_probe_timeout&#x3D;20s, gp_fts_probe_retries &#x3D; 1</span><br><span class="line"></span><br><span class="line">--场景1：</span><br><span class="line">begin;</span><br><span class="line"></span><br><span class="line">-- 使用iptables 模拟一个primary segment网络故障</span><br><span class="line">-- 等fts 检测到故障并切换,然后恢复网络故障</span><br><span class="line"></span><br><span class="line">insert into test values(20),(21),(22);</span><br><span class="line">commit;</span><br><span class="line"></span><br><span class="line">--场景2：</span><br><span class="line">-- 恢复集群到初始状态</span><br><span class="line">begin;</span><br><span class="line">insert into test values(30),(31),(32);</span><br><span class="line"></span><br><span class="line">-- 使用iptables 模拟一个primary segment网络故障</span><br><span class="line">-- 等fts 检测到故障并切换后</span><br><span class="line">commit;</span><br></pre></td></tr></table></figure><p>查看事务是否能正常提交？？<br>场景1：<br><img src="/2020/12/28/Greenplum-Fts%E5%AE%9E%E7%8E%B0/case1.png" alt="image.png"><br>这个是为什么？？？<br>场景2：</p><p><img src="/2020/12/28/Greenplum-Fts%E5%AE%9E%E7%8E%B0/case2.png" alt="image.png"><br>不过master端还是发现了切换：<br><img src="/2020/12/28/Greenplum-Fts%E5%AE%9E%E7%8E%B0/case2-1.png" alt="image.png"><br>这个是因为checkDispatchResult在poll时，发现超时了，然后调用了checkSegmentAlive，看看节点是否有问题，发现该节点已经发生了切换，所以就报出了上面的错误。poll超时的原因是旧的primary在等待commit xlog同步到mirror，但是mirror已经不存在了(promote为新的primary了)。</p><p>这个是通过强同步来保证没有问题的，所以如果primary和mirror不是强同步的话，则就有问题了。所以可以得出一个结论：<strong>在非强同步时，会出现双写问题。</strong><br><strong>不过我试了一下，数据确实会不一致，但不是因为双写造成的，还不确定到底是什么原因。旧primary在提交时出现下面的错误：</strong><br><strong><img src="/2020/12/28/Greenplum-Fts%E5%AE%9E%E7%8E%B0/case2-2.png" alt="image.png"></strong><br><strong>上面的错误是重试之后的错误，在提交时为什么会失败？原因是在prepared commit之后会回收gang，在回收时会检查对应的segmeng是否down了，如果down了，则不回收gang。</strong><br><strong>所以要制造这个问题需要在执行prepared commit之后，hang住master，然后在制造网络故障。</strong><br>**</p><ol start="2"><li><strong>sync_standbys_defined的维护是有时间窗口的，如果在这个时间窗口内出现上面的问题呢？</strong></li></ol><p>有哪些情况sync_standbys_defined是null的？<br>没有mirror<br>fts认为mirror down了，primary 关闭sync_standbys_defined<br>mirror promote之前，关闭sync_standbys_defined</p><p><strong>【备注】</strong><br><strong>Q: 什么时候会走doNotifyingCommitNotPrepared？</strong><br>A: 显示的只读事务，优化了两阶段提交，比如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">begin</span>;</span><br><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> test;</span><br><span class="line"><span class="keyword">commit</span>;</span><br></pre></td></tr></table></figure><p><strong>Q: sync_standbys_defined 与 SyncCommitLevel的关系？？</strong><br>**A: **sync_standbys_defined 表示是否有强同步的节点在，如果不为空的话，则表示数据一定要同步到mirror上才能结束事务，不论是否有活的mirror存在。SyncCommitLevel则表示同步级别。表示完成了哪些级别就任务是同步结束了。如果sync_standbys_defined 为false，则即使把SyncCommitLevel配置成最高级别也没有用。commit也会立即返回，不会等待同步到mirror上。具体参考SyncRepWaitForLSN函数代码。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Greenplum 总共存在2个角色，每个角色有分别实现了standby，分别是：master和master的standby， primary segment和mirror segment。数据库的fault tolerance由fault tolerance server（简称FTS）来处理。&lt;br&gt;FTS主要监控和控制segment节点的状态，以及发生异常时进行切换，FTS并不监控standby的状态，目前的实现是由管控控制。&lt;br&gt;    FTS 由2类进程组成：ftsprobe 进程和 fts handle message 进程，ftsprobe 进程在master上，定期给segment发送探活消息， fts handle message 进程是segment上处理ftsprobe 进程探活消息的，改进程不是守护进程，处理完一次探活后，即退出。&lt;/p&gt;</summary>
    
    
    
    <category term="greenplum6.0" scheme="https://zisedeqing.github.io/categories/greenplum6-0/"/>
    
    <category term="ha" scheme="https://zisedeqing.github.io/categories/greenplum6-0/ha/"/>
    
    
    <category term="greenplum" scheme="https://zisedeqing.github.io/tags/greenplum/"/>
    
    <category term="fts" scheme="https://zisedeqing.github.io/tags/fts/"/>
    
  </entry>
  
  <entry>
    <title>Greenplum shared snapshot</title>
    <link href="https://zisedeqing.github.io/2020/12/28/Greenplum-shared-snapshot/"/>
    <id>https://zisedeqing.github.io/2020/12/28/Greenplum-shared-snapshot/</id>
    <published>2020-12-28T13:33:03.000Z</published>
    <updated>2020-12-29T01:32:53.309Z</updated>
    
    <content type="html"><![CDATA[<p>shared snapshot是gp新引入的一个机制，用于在每个segment上同一个transaction的QE writer与QE reader之间共享snapshot。</p><a id="more"></a><h1 id="引入的原因"><a href="#引入的原因" class="headerlink" title="引入的原因"></a>引入的原因</h1><p>gp为了提升查询性能，把一个plan会查分成多个slice，每个slice在segment上就是一个可以独立运行的执行单元，多个slice使用树形结构组织，数据从下面的slice流向上面的slice，并行执行。每个slice实际上就对应于segment上的一个backend进程(gp称为QE)， 在gp中有两种QE，QE writer和QE reader (分别对应于writer gang和reader gang)。在segment上transaction的所有数据写入操作只能由QE writer来做，但是QE writer和QE reader又属于同一个transaction，所以QE writer和QE reader必须使用相同的snapshot，才能保证数据的一致性。QE writer和QE reader在segment上又是单独backend，所以对于pg来说，他们应该是2个不同的transaction，看到的数据也是不一样的。所以gp就引入了shared snapshot来解决这个问题。</p><h1 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h1><p>QE writer把snapshot 写入共享内存中，QE writer在需要snapshot时，根据mpp_session_id在共享内存中查找QE writer生成的snapshot，这样就使用了与QE writer相同的snapshot，对于数据的可见性也保证了。</p><h1 id="share了哪些"><a href="#share了哪些" class="headerlink" title="share了哪些"></a>share了哪些</h1><p>snapshot<br>sub-transaction status<br>combo-cid mapping<br>等</p><h1 id="关于cursor的处理"><a href="#关于cursor的处理" class="headerlink" title="关于cursor的处理"></a>关于cursor的处理</h1><p>shared snapshot在设计的初衷是满足一般sql的，即执行时使用的是current snapshot，但是cursor使用的snapshot是cursor创建时的snapshot，不是current snapshot。并且cursor还有一个不同的地方是，对于同一个transaction是可以由多个cursor同时存在的，这样就需要存储多个snapshot。<br>gp解决这个问题的方式是，把current snapshot 写入临时文件，QE reader使用时，从临时文件读取对应的snapshot，而不是使用共享内存中的shared snapshot。<br>细节可以看一下：<a href="https://github.com/greenplum-db/gpdb/blob/master/src/backend/utils/time/sharedsnapshot.c">https://github.com/greenplum-db/gpdb/blob/master/src/backend/utils/time/sharedsnapshot.c</a> 文件头注释。</p><h1 id="相关代码"><a href="#相关代码" class="headerlink" title="相关代码"></a>相关代码</h1><p>我们使用的gp版本（4.3.99）shared snapshot代码在tqual.c里面的，后面gp把这块代码单独领出来了。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">SharedSnapshotStruct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">int</span> numSlots;<span class="comment">/* number of valid Snapshot entries */</span></span><br><span class="line"><span class="keyword">int</span>maxSlots;<span class="comment">/* allocated size of sharedSnapshotArray */</span></span><br><span class="line"><span class="keyword">int</span> nextSlot;<span class="comment">/* points to the next avail slot. */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * We now allow direct indexing into this array.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * We allocate the XIPS below.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Be very careful when accessing fields inside here.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">SharedSnapshotSlot   *slots;</span><br><span class="line"></span><br><span class="line">TransactionId   *xips;<span class="comment">/* VARIABLE LENGTH ARRAY */</span></span><br><span class="line">&#125; SharedSnapshotStruct;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">volatile</span> SharedSnapshotStruct *sharedSnapshotArray;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">SharedSnapshotSlot</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">int4slotindex;  <span class="comment">/* where in the array this one is. */</span></span><br><span class="line">int4 slotid;</span><br><span class="line"><span class="keyword">pid_t</span> pid; <span class="comment">/* pid of writer seg */</span></span><br><span class="line">TransactionIdxid;</span><br><span class="line">CommandId       cid;</span><br><span class="line">TimestampTzstartTimestamp;</span><br><span class="line"><span class="keyword">volatile</span> TransactionId   QDxid;</span><br><span class="line"><span class="keyword">volatile</span> CommandIdQDcid;</span><br><span class="line"><span class="keyword">volatile</span> <span class="keyword">bool</span>ready;</span><br><span class="line"><span class="keyword">volatile</span> uint32segmateSync;</span><br><span class="line">uint32total_subcnt;<span class="comment">/* Total # of subxids */</span></span><br><span class="line">uint32inmemory_subcnt;    <span class="comment">/* subxids in memory */</span></span><br><span class="line">TransactionId   subxids[MaxGpSavePoints];</span><br><span class="line">uint32combocidcnt;</span><br><span class="line">ComboCidKeyData combocids[MaxComboCids];</span><br><span class="line">SnapshotDatasnapshot;</span><br><span class="line"></span><br><span class="line">&#125; SharedSnapshotSlot;</span><br><span class="line"></span><br><span class="line"><span class="keyword">volatile</span> SharedSnapshotSlot *SharedLocalSnapshotSlot = <span class="literal">NULL</span>;</span><br></pre></td></tr></table></figure><p>CreateSharedSnapshotArray:<br>创建并初始化sharedSnapshotArray<br><img src="/2020/12/28/Greenplum-shared-snapshot/CreateSharedSnapshotArray.png" alt="CreateSharedSnapshotArray"><br>addSharedSnapshot：<br>初始化当前session的shared snapshot并插入到sharedSnapshotArray。<br>初始化SharedLocalSnapshotSlot<br>role: GP_ROLE_DISPATCH || (GP_ROLE_EXECUTE &amp;&amp; Gp_is_writer)</p><p><img src="/2020/12/28/Greenplum-shared-snapshot/addSharedSnapshot.png" alt="addSharedSnapshot"></p><p>lookupSharedSnapshot:<br>从sharedSnapshotArray中找到当前session对应的shared snapshot,并赋给SharedLocalSnapshotSlot<br>role: Entry db singleton QE || (GP_ROLE_EXECUTE &amp;&amp; !Gp_is_writer)<br><img src="/2020/12/28/Greenplum-shared-snapshot/lookupSharedSnapshot.png" alt="lookupSharedSnapshot"></p><p>SharedSnapshotRemove：<br>回收当前session占用的shared snapshot slot 给sharedSnapshotArray<br><img src="/2020/12/28/Greenplum-shared-snapshot/SharedSnapshotRemove.png" alt="SharedSnapshotRemove"></p><p>dumpSharedLocalSnapshot_forCursor<br>把SharedLocalSnapshotSlot dump到文件<br>只有在extended query (declare cusor/PBE protocol)时才会走该流程，由master调用verify_shared_snapshot_ready让所有的节点执行dump。<br>    <img src="/2020/12/28/Greenplum-shared-snapshot/dumpSharedLocalSnapshot_forCursor.png" alt="dumpSharedLocalSnapshot_forCursor"><br>readSharedLocalSnapshot_forCursor<br>从dump的文件恢复shared snapshot，只有extended query时才会走该流程<br>    <img src="/2020/12/28/Greenplum-shared-snapshot/readSharedLocalSnapshot_forCursor.png" alt="readSharedLocalSnapshot_forCursor"></p><p>updateSharedLocalSnapshot<br>更新SharedLocalSnapshotSlot<br>    <img src="/2020/12/28/Greenplum-shared-snapshot/updateSharedLocalSnapshot.png" alt="updateSharedLocalSnapshot"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;shared snapshot是gp新引入的一个机制，用于在每个segment上同一个transaction的QE writer与QE reader之间共享snapshot。&lt;/p&gt;</summary>
    
    
    
    <category term="greenplum4.3" scheme="https://zisedeqing.github.io/categories/greenplum4-3/"/>
    
    <category term="transaction" scheme="https://zisedeqing.github.io/categories/greenplum4-3/transaction/"/>
    
    
    <category term="greenplum" scheme="https://zisedeqing.github.io/tags/greenplum/"/>
    
    <category term="snapshot" scheme="https://zisedeqing.github.io/tags/snapshot/"/>
    
  </entry>
  
  <entry>
    <title>Greenplum 列存原理分析</title>
    <link href="https://zisedeqing.github.io/2020/12/28/Greenplum-%E5%88%97%E5%AD%98%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/"/>
    <id>https://zisedeqing.github.io/2020/12/28/Greenplum-%E5%88%97%E5%AD%98%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/</id>
    <published>2020-12-28T13:15:43.000Z</published>
    <updated>2020-12-29T01:32:53.309Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-相关代码"><a href="#1-相关代码" class="headerlink" title="1. 相关代码"></a>1. 相关代码</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">src&#x2F;backend&#x2F;access&#x2F;aocs</span><br><span class="line">                    aocs_compaction.c</span><br><span class="line">                    aocsam.c</span><br><span class="line">                    aocssegfiles.c</span><br><span class="line">                &#x2F;appendonly</span><br><span class="line">                    appendonlyam.c</span><br><span class="line">                    aomd.c</span><br><span class="line">                    aosegfiles.c</span><br><span class="line">                    appendonly_compaction.c</span><br><span class="line">                    appendonly_visimap.c</span><br><span class="line">                    appendonly_visimap_entry.c</span><br><span class="line">                    appendonly_visimap_store.c</span><br><span class="line">                    appendonly_visimap_udf.c</span><br><span class="line">                    appendonlyblockdirectory.c</span><br><span class="line">                    appendonlytid.c</span><br><span class="line">                    appendonlywriter.c</span><br><span class="line">src&#x2F;backend&#x2F;utils&#x2F;datumstream</span><br><span class="line">                    datumstream.c</span><br><span class="line">                    datumstreamblock.c</span><br><span class="line">src&#x2F;backend&#x2F;cdb&#x2F;</span><br><span class="line">                cdbbufferedappend.c</span><br><span class="line">                cdbbufferedread.c</span><br></pre></td></tr></table></figure><a id="more"></a><h1 id="2-组织结构"><a href="#2-组织结构" class="headerlink" title="2. 组织结构"></a>2. 组织结构</h1><p><img src="/2020/12/28/Greenplum-%E5%88%97%E5%AD%98%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/aocs-%E7%BB%84%E7%BB%87%E7%BB%93%E6%9E%84%E5%9B%BE.png" alt="aocs-组织结构图"></p><h2 id="2-1-segfile"><a href="#2-1-segfile" class="headerlink" title="2.1 segfile"></a>2.1 segfile</h2><ol><li>不同的列存储在不同的文件内，</li><li>一个列的物理文件最多只有128个</li><li>列文件以block为单位组织，压缩后的block大小不一，并且该文件没有文件头信息。</li><li>压缩之前的block大小也不是固定的，根据当前事务的写入量而定。</li><li>segfile size没有限制，只限制一个segfile最多存储的行数：2^40-1 (约10095亿)。并且默认情况下在存储到达90%时，会切换新的文件(具体细节查看SetSegnoForWrite函数) </li></ol><p>gp的segfile存在溢出bug，gp在insert to segfile时并不会检查rowcount是否超过2^40-1，所以如果再同一个事务内插入大量数据到一个将要满的segfile，就可能会导致文件溢出。而这个溢出操作并不会导致数据库报错，而是rownum &gt; 2^40-1的数据都会丢失。</p><h2 id="2-2-rownum"><a href="#2-2-rownum" class="headerlink" title="2.2 rownum"></a>2.2 rownum</h2><h3 id="2-2-1-为何引入rownum"><a href="#2-2-1-为何引入rownum" class="headerlink" title="2.2.1 为何引入rownum"></a>2.2.1 为何引入rownum</h3><p>对于heap表，pg使用tid表示tuple的物理位置，但是对于aocs表，由于压缩的原因，无法确定一个tuple在文件中的物理位置，所以gp引入了rownum表示tuple在文件中的逻辑位置。</p><ol><li>rownum 是递增的，但可能不连续，不连续的原因是insert时为了效率每次都是生成一批rownum</li><li>每个tuple都唯一的对应一个rownum，与tid一样</li><li>不同的segfile的tuple rownum单独计算</li></ol><p>所以在同一个block内，rownum一定是连续的</p><ol start="4"><li>如何使用rownum找到对应的tuple</li></ol><p>首先block header记录的当前block的第一个rownum和rowcount，所以只需要遍历整个文件，如果rownum 在[firstrownum, firstrownum+rowcount]范围内，则找到tuple对应的 block，遍历block即可。</p><h3 id="2-2-2-aocs的tuple-id"><a href="#2-2-2-aocs的tuple-id" class="headerlink" title="2.2.2 aocs的tuple id"></a>2.2.2 aocs的tuple id</h3><p>gp使用AOTupleId 表示tuple id(与pg的tid对应，heap表使用ItemPointer表示tid)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">typedef struct AOTupleId</span><br><span class="line">&#123;</span><br><span class="line">uint16      bytes_0_1;</span><br><span class="line">uint16bytes_2_3;</span><br><span class="line">uint16bytes_4_5;</span><br><span class="line"></span><br><span class="line">&#125; AOTupleId;</span><br></pre></td></tr></table></figure><p>最左7位是segment no，所以最多只有128文件<br>最右的第16位是保留位，一定是1<br>剩下的40位元组在文件的位置标记，即rownum。<br>如下图所示：<br><img src="/2020/12/28/Greenplum-%E5%88%97%E5%AD%98%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/rownum.png" alt="rownum"></p><ul><li><input checked disabled type="checkbox"> <strong>为什么第33位要标记为1？</strong></li></ul><p>主要原因是AOTupleId在一些地方如executor等会转换成行存的Itempointer，在代码中有很多ItemPointerIsValid的判断，为了简单gp把第33位标记为1.<br>实际上要过ItemPointerIsValid的判断，只需要把最后16位的任意一位标记为1即可，不确定为什么选择最后16位的第一个位。</p><h2 id="2-3-block"><a href="#2-3-block" class="headerlink" title="2.3 block"></a>2.3 block</h2><p>对于列存的block，每个block有2个header，一个是block header，另一个是datum header。其中block header是不会压缩的，datum header会压缩。</p><h3 id="2-3-1-header"><a href="#2-3-1-header" class="headerlink" title="2.3.1 header"></a>2.3.1 header</h3><ul><li><input checked disabled type="checkbox"> <strong>block header</strong></li></ul><p>block header size： 8bytes + 8bytes + 4 bytes = 20 bytes<br><img src="/2020/12/28/Greenplum-%E5%88%97%E5%AD%98%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/block-header.png" alt="block header"><br>类型：</p><ol><li>AoHeaderKind_SmallContent  一般的<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">AOSmallContentHeader</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">      uint32            smallcontent_bytes_0_3;</span><br><span class="line">      uint32            smallcontent_bytes_4_7;</span><br><span class="line">&#125;AOSmallContentHeader</span><br></pre></td></tr></table></figure></li><li>AoHeaderKind_LargeContent 超长字段，一个block存不下，分成多个block存储</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">typedef struct AOLargeContentHeader</span><br><span class="line">&#123;</span><br><span class="line">    uint32            largecontent_bytes_0_3;</span><br><span class="line">    uint32            largecontent_bytes_4_7;</span><br><span class="line">&#125;AOLargeContentHeader</span><br></pre></td></tr></table></figure><p>如果一个字段长度超长，则会被分割成多个block存储，方式是：<br>large block|small block|…|small block</p><ol start="3"><li>AoHeaderKind_NonBulkDenseContent </li></ol><p>column compress type = rle_type<br>column compress level = 1 &amp;&amp;<br>rowcount &gt; 16383</p><ol start="4"><li>AoHeaderKind_BulkDenseContent</li></ol><p>column compress type = rle_type<br>column compress level &gt; 1 &amp;&amp;<br>rowcount &gt; 16383<br><strong>未看到哪种情况会走这个</strong></p><p>[x] <strong>datum header</strong><br>类型：</p><ol><li>DatumStreamVersion_Original</li></ol><p>无压缩或者zlib压缩</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Datum Stream Block (Original).</span></span><br><span class="line"><span class="comment"> * 16 bytes header.  Followed by data.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">DatumStreamBlock_Orig</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">int16version;<span class="comment">/* version number */</span></span><br><span class="line">int16flags;<span class="comment">/* some flags */</span></span><br><span class="line">int16ndatum;<span class="comment">/* number of datum, including null */</span></span><br><span class="line">int16unused;<span class="comment">/* unused */</span></span><br><span class="line">int32nullsz;<span class="comment">/* size nullbitmaps */</span></span><br><span class="line">int32sz;<span class="comment">/* logical data size, not including header,</span></span><br><span class="line"><span class="comment"> * nullbitmap, and padding */</span></span><br><span class="line">&#125;DatumStreamBlock_Orig;</span><br></pre></td></tr></table></figure><ol start="2"><li>DatumStreamVersion_Dense</li></ol><p>目前版本无该类型的block，猜测是用于quicklz压缩的</p><ol start="3"><li>DatumStreamVersion_Dense_Enhanced</li></ol><p>压缩类型为: RLE_TYPE<br>DatumStreamBlock_Dense<br>DatumStreamBlock_Rle_Extension<br>DatumStreamBlock_Delta_Extension</p><h3 id="2-3-2-block-size"><a href="#2-3-2-block-size" class="headerlink" title="2.3.2 block size"></a>2.3.2 block size</h3><p>列存block size 范围：[8KB, 2MB]，压缩之前的size<br>默认size是：32KB<br>真实的block size受限于用户建表时定义的blocksize，如果没有指定blocksize，则使用默认的blocksize。<br>还有一个参数会影响block size，就是gp列存限定了一个block最多可以存多少个value，如果超过这个值，即使没有达到block size限制还是会写入到另外的block内的。</p><ol><li>DatumStreamVersion_Original</li></ol><p>最多16383行, 即small content header row count最大值：2^14 - 1</p><ol start="2"><li>DatumStreamVersion_Dense/DatumStreamVersion_Dense_Enhanced</li></ol><p>最多2^30 -1行, 即noblukdense header row count最大值</p><h3 id="2-3-3-null-bitmap"><a href="#2-3-3-null-bitmap" class="headerlink" title="2.3.3 null bitmap"></a>2.3.3 null bitmap</h3><p>用来存储null值</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">DatumStreamBitMapWrite</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">uint8   *buffer;</span><br><span class="line">int32bufferSize;</span><br><span class="line"></span><br><span class="line">uint8byteBit;</span><br><span class="line">uint8   *bytePointer;</span><br><span class="line">int32bitOnCount;</span><br><span class="line">int32bitCount;</span><br><span class="line">&#125;DatumStreamBitMapWrite;</span><br></pre></td></tr></table></figure><h1 id="3-辅助元信息表"><a href="#3-辅助元信息表" class="headerlink" title="3. 辅助元信息表"></a>3. 辅助元信息表</h1><h2 id="3-1-库级别的meta表"><a href="#3-1-库级别的meta表" class="headerlink" title="3.1 库级别的meta表"></a>3.1 库级别的meta表</h2><p>pg_appendonly gp原有的，记录所有的appendonly表<br>gp_fastsequence rownum使用的sequence，segment上的有用</p><h2 id="3-2-表级别的meta表"><a href="#3-2-表级别的meta表" class="headerlink" title="3.2 表级别的meta表"></a>3.2 表级别的meta表</h2><p>下面的meta表是对于每个ao表都有，如果表是分区表，则每个自分区也都会有下面这些meta表。</p><h3 id="3-2-1-查询方法"><a href="#3-2-1-查询方法" class="headerlink" title="3.2.1 查询方法"></a>3.2.1 查询方法</h3><p>SELECT gp_segment_id, * from gp_dist_random(‘pg_aoseg.pg_aoblkdir_17684’)<br>注意使用utility直接登录segment查询是不行的，估计是可见性问题吧</p><h3 id="3-2-2-pg-aocsseg-XXX"><a href="#3-2-2-pg-aocsseg-XXX" class="headerlink" title="3.2.2 pg_aocsseg_XXX"></a>3.2.2 pg_aocsseg_XXX</h3><p>记录segfile 相关信息，包含元组数量、文件长度、修改次数等。</p><table><thead><tr><th>column</th><th>type</th><th>desc</th></tr></thead><tbody><tr><td>segno</td><td>integer</td><td>文件号，表示第几个文件。对应于真实的文件是:</td></tr><tr><td>relfilenode.segno+（column_number - 1）* 128</td><td></td><td></td></tr><tr><td>比如relfilenode=451012的第二列的segno=2的文件名是：</td><td></td><td></td></tr><tr><td>451012.130</td><td></td><td></td></tr><tr><td>tupcount</td><td>bigint</td><td>元组数量，包含已经删除的和更新的。如果这个值与select count(*)差距比较大的话，就说明垃圾数据较多，需要做vacuum</td></tr><tr><td>varblockcount</td><td>bigint</td><td></td></tr><tr><td>vpinfo</td><td>bytea</td><td>记录文件长度，包含真实的eof和未压缩后的eof</td></tr><tr><td>modcount</td><td>bigint</td><td>文件修改次数</td></tr><tr><td>state</td><td>smallint</td><td>文件状态：USECURRENT/DEFAULT/AWAITING_DROP</td></tr></tbody></table><p>一个例子：<br><img src="/2020/12/28/Greenplum-%E5%88%97%E5%AD%98%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/pg_aocsseg_XXX.png" alt="pg_aocsseg_XXX"></p><h3 id="3-2-3-pg-aovisimap-XXX"><a href="#3-2-3-pg-aovisimap-XXX" class="headerlink" title="3.2.3 pg_aovisimap_XXX"></a>3.2.3 pg_aovisimap_XXX</h3><p>记录segfile里面的元组可见性信息，主要作用于update/delete，对于rollback导致的不可见是由pg_aocsseg_xxx里面记录的文件长度保证的。</p><table><thead><tr><th>column</th><th>type</th><th>desc</th></tr></thead><tbody><tr><td>segno</td><td>integer</td><td>segfile number</td></tr><tr><td>first_row_no</td><td>bigint</td><td>当前范围内的第一个row num，从0开始，每个元组记录32768个元组可见性信息。</td></tr><tr><td>visimap</td><td>bit varying</td><td>记录元组可见性的bit map</td></tr></tbody></table><p>例子：<br><img src="/2020/12/28/Greenplum-%E5%88%97%E5%AD%98%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/pg_aovisimap_XXX.png" alt="pg_aovisimap_XXX"></p><p>如何判断一个rownum是否在当前visiMapEntry内：<br>bitoffset = rownum - first_row_no<br>(rownum &gt;= first_row_no &amp;&amp; rownum &lt; first_row_no + 32768) &amp;&amp;  (visimap &amp; (1&lt;&lt;bitoffset) != 0) == true ?</p><h3 id="3-2-4-pg-aoblkdir-XXX"><a href="#3-2-4-pg-aoblkdir-XXX" class="headerlink" title="3.2.4 pg_aoblkdir_XXX"></a>3.2.4 pg_aoblkdir_XXX</h3><p>块字典meta表，用于记录block位置信息。创建表的时候，默认不创建该表，在创建表的第一个index时，会创建该meta表。由于ao表的AOTupleId只记录的tuple的逻辑位置信息，不像heap的tid记录的是物理位置信息，在使用index scan时，无法通过AOTupleId直接的找到tuple，所以gp添加了pg_aoblkdir_XXX表，记录block的物理位置信息，来加上index scan tuple的fetch。<br>该系统表上以一个索引，索引列是(segno, columngroup_no, first_row_no)。</p><table><thead><tr><th>column</th><th>type</th><th>desc</th></tr></thead><tbody><tr><td>segno</td><td>integer</td><td>segfile number</td></tr><tr><td>columngroup_no</td><td>integer</td><td>column number</td></tr><tr><td>first_row_no</td><td>bigint</td><td>该行覆盖的第一个tuple的rownum</td></tr><tr><td>minipage</td><td>bit varying</td><td>minEntry的数组，每个entry覆盖多个block</td></tr></tbody></table><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">typedef struct MinipageEntry</span><br><span class="line">&#123;</span><br><span class="line">int64 firstRowNum;   &#x2F;&#x2F; 当前entry覆盖的第一个tuple的rownum</span><br><span class="line">int64 fileOffset;    &#x2F;&#x2F; 当前entry 覆盖的第一个block在文件中的偏移，该偏移是开始位置的偏移</span><br><span class="line">int64 rowCount;      &#x2F;&#x2F; 当前entry覆盖的所有block的tuple个数 </span><br><span class="line">   &#x2F;&#x2F; (可能会比实际的个数要大，因为有些情况是计算出来的)</span><br><span class="line">&#125; MinipageEntry;</span><br><span class="line"></span><br><span class="line">typedef struct Minipage</span><br><span class="line">&#123;</span><br><span class="line">&#x2F;* Total length. Must be the first. *&#x2F;</span><br><span class="line">int32 _len;</span><br><span class="line">int32 version;</span><br><span class="line">uint32 nEntry;</span><br><span class="line"></span><br><span class="line">&#x2F;* Varlena array *&#x2F;</span><br><span class="line">MinipageEntry entry[1];</span><br><span class="line">&#125; Minipage;</span><br></pre></td></tr></table></figure><p>默认pg_aoblkdir_XXX的一行可以存储161(NUM_MINIPAGE_ENTRIES)个MinipageEntry信息， 每个MinipageEntry记录一个block的信息，但是为了提高性能，gp也提供如下方法来修改一个entry记录的block数量还有一行记录的entry数量：</p><ol><li>gp_blockdirectory_minipage_size</li></ol><p>一行记录存储的MinipageEntry数量, 取值范围是(1 .. 161)</p><ol start="2"><li>gp_blockdirectory_entry_min_range</li></ol><p>控制一个MinipageEntry 记录的数据范围，取值范围（0, INT_MAX）.<br>计算方法：<br>current_fileOffset - last MinipageEntry.fileOffset &lt; gp_blockdirectory_entry_min_range，则跳过当前block，否则把当前block的相关信息记录到新的MinipageEntry。current_fileOffset - last MinipageEntry.fileOffset 表示的就是last MinipageEntry所能覆盖的范围。<br>gp_blockdirectory_entry_min_range参数会导致MinipageEntry的覆盖范围超过一个block，但是不会小于一个block。<br>pg_aoblkdir_XXX的维护：</p><ol><li>更新<ol><li>insert new tuple时，包含update</li><li>alter table add column时</li><li>build index时，创建新的索引的时候，在scan时会更新pg_aoblkdir_XXX</li></ol></li><li>查询 – index scan， 如何使用pg_aoblkdir_XXX快速定位tuple</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">typedef struct AppendOnlyBlockDirectoryEntry</span><br><span class="line">&#123;</span><br><span class="line">struct range</span><br><span class="line">&#123;</span><br><span class="line">int64fileOffset;     &#x2F;&#x2F; current MinipageEntry.fileOffset</span><br><span class="line">int64firstRowNum;    &#x2F;&#x2F; current MinipageEntry.firstRowNum</span><br><span class="line"></span><br><span class="line">int64afterFileOffset;  &#x2F;&#x2F; next MinipageEntry.fileOffset</span><br><span class="line">int64lastRowNum;       &#x2F;&#x2F; current MinipageEntry.firstRowNum + current MinipageEntry.rowCount - 1</span><br><span class="line">&#125; range;</span><br><span class="line">&#125; AppendOnlyBlockDirectoryEntry;</span><br></pre></td></tr></table></figure><p>根据AOTupleId，算出segfile number和rownum，使用pg_aoblkdir_XXX上的索引，进行索引扫描（条件：segno=segfile number and columngroup_no = column_no and first_row_no &lt;= rownum）快速定位到 AOTupleId 所在的MiniPage。然后通过二分查找在MiniPage中查找rownum所在的block。找到block后，就可以通过fileseek直接读取block，然后遍历block即可找到对应的tuple。</p><h1 id="4-insert-update-delete"><a href="#4-insert-update-delete" class="headerlink" title="4. insert/update/delete"></a>4. insert/update/delete</h1><h2 id="4-1-insert"><a href="#4-1-insert" class="headerlink" title="4.1 insert"></a>4.1 insert</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ExecInsert&#x2F;CopyFrom</span><br><span class="line">aocs_insert_init</span><br><span class="line">  aocs_insert_values</span><br><span class="line">  </span><br><span class="line">ExecEndPlan&#x2F;CopyFrom</span><br><span class="line">aocs_insert_finish</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><input checked disabled type="checkbox"> <strong>aocs_insert_init</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">初始化AOCSInsertDesc</span><br><span class="line">open DatumStreams</span><br><span class="line">从gp_fastsequence获取rownum range</span><br><span class="line">初始化fist rownum</span><br><span class="line">初始化AppendOnlyBlockDirectory</span><br></pre></td></tr></table></figure></li><li><input checked disabled type="checkbox"> <strong>aocs_insert_values</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">for each columns</span><br><span class="line">do</span><br><span class="line">尝试把value存入当前block</span><br><span class="line">  if failed</span><br><span class="line">  把当前block写入buffer，并清空当前block</span><br><span class="line">    更新blockDirectory系统表</span><br><span class="line">  再次尝试把value写入当前block</span><br><span class="line">    if failed</span><br><span class="line"> 把value分割，写入不同的block(lob，large object)</span><br><span class="line">  更新blockDirectory系统表</span><br><span class="line">done</span><br><span class="line">set AOTupleId</span><br><span class="line">如 rownum 使用完了，从新从gp_fastsequence获取一批rownum(100)</span><br></pre></td></tr></table></figure>有几点需要注意的是：</li></ul><ol><li>如果压缩类型是rle_type，则使用lob存储时，不会进行压缩</li></ol><ul><li><input checked disabled type="checkbox"> <strong>aocs_insert_finish</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">for each columns</span><br><span class="line">do</span><br><span class="line">write block to buffer</span><br><span class="line">  update block directory catalog</span><br><span class="line">  close file</span><br><span class="line">  flush buffer content to disk</span><br><span class="line">    sync content to mirror</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">update aocs file segment information</span><br><span class="line">some cleanup job</span><br></pre></td></tr></table></figure><h2 id="4-2-delete"><a href="#4-2-delete" class="headerlink" title="4.2 delete"></a>4.2 delete</h2></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ExecDelete</span><br><span class="line">aocs_delete_init</span><br><span class="line">  aocs_delete</span><br><span class="line">  </span><br><span class="line"> ExecEndPlan</span><br><span class="line"> aocs_delete_finish</span><br></pre></td></tr></table></figure><ul><li><input checked disabled type="checkbox"> <strong>aocs_delete_init</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">初始化AOCSDeleteDesc</span><br><span class="line">初始化visibilityMap</span><br><span class="line">初始化visibilityMapDelete</span><br></pre></td></tr></table></figure><ul><li><p><strong>aocs_delete</strong><br>比较简单就是把visibilityMap上对应的位置标记为1<br>主要工作在AppendOnlyVisimapDelete_Hide里面完成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if tuple不在current_Visimap_Entry内</span><br><span class="line">if current_Visimap_Entry is dirty</span><br><span class="line">  把current_Visimap_Entry刷入外存(使用work file组织)</span><br><span class="line">  查找tuple对应的visimap entry并加装到current_Visimap_Entry</span><br><span class="line">标记current_Visimap_Entry 对应的bit为1，并设置为dirty</span><br></pre></td></tr></table></figure><p>对于pg_aovisimap_XXX 系统表的修改，gp这里做了一个特殊处理，原有系统表的修改是通过shared_buffer来做的，没改一次要修改一次shared_buffer并记录xlog。这里gp对于pg_aovisimap_XXX 的修改做了优化，把同一条语句内多次修改pg_aovisimap_XXX 的操作合并成了，这样可以减少pg_aovisimap_XXX 的更新次数已经xlog量。合并的方式是：对应pg_aovisimap_XXX 的修改先记录到内存，如果内存放不下，则写入到work file内，在最后语句结束的是在把内存和work file内的修改更新到pg_aovisimap_XXX 上。<br>这样做的出发点：</p><ol><li>减少pg_aovisimap_XXX由于更新导致的过度膨胀</li><li>减少xlog，可以提高mirror同步效率</li></ol></li><li><p><strong>aocs_delete_finish</strong></p></li></ul><p>主要是把内存中的visimap entry 和work file内的entry 合并然后更新到pg_aovisimap_XXX</p><h2 id="4-3-update"><a href="#4-3-update" class="headerlink" title="4.3 update"></a>4.3 update</h2><p>update操作实际就是 delete + insert，代码上也基本是这样实现的，没啥好说的。<br>有一点是，虽然是列存，但是update的时候还是按行来做的，即使我们只update某一列，实际上与行存一样，aocs也是把整个行标记为delete，然后insert新的行。</p><h2 id="4-4-copy-from"><a href="#4-4-copy-from" class="headerlink" title="4.4 copy from"></a>4.4 copy from</h2><p>与insert 类似</p><h2 id="4-5-iud并发控制"><a href="#4-5-iud并发控制" class="headerlink" title="4.5 iud并发控制"></a>4.5 iud并发控制</h2><ul><li><input checked disabled type="checkbox"> <strong>update/delete并发控制</strong></li></ul><p>update/delete并发控制比较简单，在执行时加表的ExclusiveLock, 把update/delete/ select for update操作串行化。<br>这样做的目的主要是防止死锁，由于gp没有全局的死锁检测机制，所以弱化update并发来解决死锁问题。<br>目前gp死锁检测处理不了的情况：<br><img src="/2020/12/28/Greenplum-%E5%88%97%E5%AD%98%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/global-deadlock.png" alt="global-deadlock"></p><ul><li><input checked disabled type="checkbox"> <strong>insert与insert的并发控制</strong></li></ul><p>对于同一个表的insert是可以并发执行的，由于列存与pg heap表不同，gp针对列存表单独实现了一个比较简单粗暴的并发控制机制：对于insert操作，每个insert进程处理不同的segfile，即insert 进程直接不会有冲突，所以也不需要加锁等控制。简单来说有2点：</p><ol><li>对于列存文件的修改，每个insert进程修改不同的segfile</li></ol><p>在insert之前，gp会为insert进程分配当前进程插入的segfile，不同的insert 进程插入不同的segfile，处理流程可以看一下SetSegnoForWrite函数的实现。</p><ol start="2"><li>对应meta表的修改，走pg heap 表，使用pg原有的并发控制机制</li></ol><ul><li><input checked disabled type="checkbox"> <strong>insert与update/delete的并发控制</strong></li></ul><p>由于update/delete需要加ExclusiveLock锁，导致insert与update/delete也无法并行执行</p><h1 id="5-scan"><a href="#5-scan" class="headerlink" title="5. scan"></a>5. scan</h1><h2 id="5-1-table-scan"><a href="#5-1-table-scan" class="headerlink" title="5.1 table scan"></a>5.1 table scan</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">aocs_beginscan</span><br><span class="line">while !done</span><br><span class="line">aocs_getnext</span><br><span class="line">aocs_endscan</span><br></pre></td></tr></table></figure><ul><li><input checked disabled type="checkbox"> <strong>aocs_beginscan</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">resourceowner table refcount+1</span><br><span class="line">GetAppendOnlyEntry</span><br><span class="line">从pg_aoseg_xxx表查询所有的segfile信息</span><br><span class="line">create AOCSScanDesc</span><br><span class="line">aocs_initscan</span><br><span class="line">  open_ds_read</span><br><span class="line">  AppendOnlyVisimap_Init</span><br></pre></td></tr></table></figure>关于scan时的snapshot：</li></ul><ol><li>current_snapshot， 正常查询的snapshot，scan之前生成</li></ol><p>tabledata_snapshot: current_snapshot<br>metadata_snapshot: current_snapshot</p><ol start="2"><li>SnapshotAny，开启gp_select_invisible后使用，用于查询历史数据。</li></ol><p>tabledata_snapshot: SnapshotAny<br>aocs表tuple上是没有事务信息的，这个snapshot主要是用来配合pg_visimap_xxx系统表的<br>metadata_snapshot: current_snapshot</p><ul><li><p><strong>aocs_endscan</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">resourceowner table refcount-1</span><br><span class="line">destory AOCSScanDesc</span><br><span class="line">close_cur_scan_seg</span><br><span class="line">  close_ds_read</span><br><span class="line">  AppendOnlyVisimap_Finish</span><br></pre></td></tr></table></figure></li><li><p><strong>aocs_getnext</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line">READ_NEXT:</span><br><span class="line"><span class="keyword">if</span> necessary, open next segfile;</span><br><span class="line">    <span class="keyword">if</span> (No more seg)</span><br><span class="line">  <span class="keyword">return</span>;</span><br><span class="line">    </span><br><span class="line">  foreach_columns</span><br><span class="line">  &#123;</span><br><span class="line">  <span class="keyword">if</span> (scan-&gt;proj[i] == <span class="literal">false</span>)</span><br><span class="line">    <span class="comment">// 查询没有使用到该column，skip read</span></span><br><span class="line">    <span class="keyword">continue</span>;</span><br><span class="line">      </span><br><span class="line">   <span class="comment">//当前block的current_tuple 后移，类似于jdbc ResultSet.next</span></span><br><span class="line">    datumstreamread_advance;</span><br><span class="line">    <span class="keyword">if</span> (no tuple)</span><br><span class="line">    &#123;</span><br><span class="line">            <span class="comment">// read next block</span></span><br><span class="line">            datumstreamread_block;</span><br><span class="line">            <span class="keyword">if</span> (end of file)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">goto</span> READ_NEXT;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> necessary, insert block directory meta entry;</span><br><span class="line">            datumstreamread_advance;</span><br><span class="line">    &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// get current column value</span></span><br><span class="line">        datumstreamread_get</span><br><span class="line">  &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">set</span> AOTupleId</span><br><span class="line">    数据可见性判断，如果不可见 <span class="keyword">goto</span> READ_NEXT;</span><br><span class="line">    save current tuple <span class="keyword">and</span> AOTupleId;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><ol><li>对于查询未涉及的column，read时自动跳过，减少io</li><li>数据可见性判断<ul><li>如果tabledata_snapshot是SnapshotAny，则跳过可见性判断</li><li>否则，通过visimap判断tuple是否已经被删除</li></ul></li></ol><ul><li><input checked disabled type="checkbox"> <strong>aocs_getnext_comp</strong></li></ul><p>开启向量化后，aocs scan接口。与aocs_getnext的不同之处在于：</p><ol><li>aocs_getnext每次读取一个tuple，然后就返回，而aocs_getnext_comp是每次读取一批tuple。</li><li>对于向量化，会有一些谓词下推，所以aocs_getnext_comp会做一些filter<h2 id="5-2-index-scan"><a href="#5-2-index-scan" class="headerlink" title="5.2 index scan"></a>5.2 index scan</h2>aocs上的索引扫描<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">BitmapAppendOnlyScanNext</span><br><span class="line">aocs_fetch_init</span><br><span class="line">  aocs_fetch</span><br><span class="line">aocs_fetch_finish</span><br></pre></td></tr></table></figure>aocs_fetch：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">foreach_columns</span><br><span class="line">&#123;</span><br><span class="line">从BlockDirectoryEntry找到tuple所在block</span><br><span class="line">    从block中读取tuple</span><br><span class="line">    判断tuple可见性</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p>可优化的地方：</p><ol><li>先做可见性判断在读block</li></ol><p>目前做可见性判断时是先把tuple所在block 从disk读到内存，然后在判断可见性。实际上aocs的可见性信息是记录在pg_aovisimap表里面的，可以先判断可见性，再读block，这样如果不可见可以减少不必须的io。</p><ol start="2"><li>第一列通过可见性判断后，后面列可以跳过可见性判断</li></ol><p>rownum是tuple的唯一标识，如果tuple的第一列通过了可见性判断，则后面所有的列也是可见的，因此是不需要再做可见性判断的</p><h2 id="5-3-header-scan"><a href="#5-3-header-scan" class="headerlink" title="5.3 header scan"></a>5.3 header scan</h2><p>alter table add column 是调用，粗略看了一下代码，主要是用来辅助创建新的column对应的segfile的。header scan实际上扫描的时候只是把block读取出来，并不会把block解压，主要是使用block上的header信息。<br>有两点：</p><ol><li>ao表 添加新的column时，必须指定default value</li><li>新segfile与之前column的segfile在结构完基本一样，比如每个block记录多少个tuple等<h2 id="5-4-tid-scan"><a href="#5-4-tid-scan" class="headerlink" title="5.4 tid scan"></a>5.4 tid scan</h2>ao表没有tid scan，只有heap表有<h2 id="5-5-range-scan"><a href="#5-5-range-scan" class="headerlink" title="5.5 range scan"></a>5.5 range scan</h2>主要是做compaction 时使用。与 table scan类似，不同之处是每次只扫描指定的几个segfile，而不是扫描所有的segfile。<h1 id="6-事务ACID"><a href="#6-事务ACID" class="headerlink" title="6. 事务ACID"></a>6. 事务ACID</h1>aocs实现了类似heap的mvcc，并且支持完整的事务ACID。aocs表数据分为两种：一是用户数据，二是meta数据。用户数据存储在segfile中，只存储数据，不存储任何事务信息(与heap表不同)，commit之前一定会flush到磁盘；meta数据存储在heap表中，通过分布式事务保证。<br>aocs的实现事务的meta表有2个 pg_aocsseg_xxx和pg_aovisimap_xxx，其中pg_aocsseg_xxx记录数据文件的逻辑长度(即当前事务可以看到的长度)；pg_aovisimap_xxx记录delete tuple，即哪些tuple被删除了。</li></ol><ul><li><input checked disabled type="checkbox"> <strong>insert</strong></li></ul><p><img src="/2020/12/28/Greenplum-%E5%88%97%E5%AD%98%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/insert.png" alt="insert"></p><ul><li><input checked disabled type="checkbox"> <strong>update</strong></li></ul><p><img src="/2020/12/28/Greenplum-%E5%88%97%E5%AD%98%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/update.png" alt="update"></p><h1 id="7-aocs-compaction"><a href="#7-aocs-compaction" class="headerlink" title="7. aocs compaction"></a>7. aocs compaction</h1><p>类似于heap表的vacuum，用来清理 delete的tuple或者rollback后残留的tuple。<br>gp对vacuum操作进行了改造，目的是为了适应分布式系统，把原来pg的一个vacuum分成了几个阶段，每个阶段使用一个分布式事务。<br>对于ao表分为4个阶段：</p><ol><li>prepare phase</li></ol><p>truncate unnecessary blocks after the logical EOF</p><ol start="2"><li>compaction phase</li><li>drop phase</li></ol><p>删除compaction phase的segfile</p><ol start="4"><li>cleanup phase</li></ol><p>does normal heap vacuum on auxiliary relations (toast, aoseg, block directory, visimap,) as well as updating stats info in catalog</p><p>compaction主要有两种操作：</p><ol><li>AOCSCompaction_DropSegmentFile</li></ol><p>删掉AOSEG_STATE_AWAITING_DROP状态的segfile。在vacuum的drop phase做。</p><ol start="2"><li>AOCSTruncateToEOF</li></ol><p>在不满足compaction条件时，做truncate，这操作主要是清理最近rollback的事务残留在文件尾部的tuple。</p><ol start="3"><li>AOCSSegmentFileFullCompaction</li></ol><ul><li><input checked disabled type="checkbox"> 触发sql</li></ul><p>vacuum<br>vacuum full</p><ul><li><input checked disabled type="checkbox"> 哪些情况会做</li></ul><p>AppendOnlyCompaction_ShouldCompact</p><ol><li>vacuum full 且有delete</li><li>删除的tuple所占比例大于gp_appendonly_compaction_threshold</li></ol><ul><li><input checked disabled type="checkbox"> 如何做compaction</li></ul><p>compaction的做法比较简单：</p><ol><li>选择一个segfile做compaction，然后再选择一个segfile作为insert segfile。</li><li>遍历compaction segfile的每个tuple，如果可见(snapshot为SnapshotNow)则插入到insert segfile，如果不可见则删除。</li><li>set compaction segfile为AOSEG_STATE_AWAITING_DROP</li><li>delete visimap和block directory 中对应segno的数据</li></ol><p>insert segfile的选择：<br>选择tuple数最小的segfile或者当前vacuum事务正在使用的segfile作为insert segfile。</p><ul><li><input checked disabled type="checkbox"> 相关guc参数<table><thead><tr><th>参数名</th><th></th></tr></thead><tbody><tr><td>gp_appendonly_compaction</td><td>是否开启compaction，如果是off，则vacuum时只需TruncateToEOF</td></tr><tr><td>gp_appendonly_compaction_threshold</td><td>compaction 的阈值</td></tr><tr><td>Debug_appendonly_print_compaction</td><td>输出debug信息</td></tr></tbody></table></li></ul><ol start="8"><li>aocs表的一些限制</li></ol><ul><li><input checked disabled type="checkbox"> <strong>不支持unique index</strong></li></ul><p>不支持的原因是在检查到冲突的tuple后，无法判断该tuple的事务信息。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;1-相关代码&quot;&gt;&lt;a href=&quot;#1-相关代码&quot; class=&quot;headerlink&quot; title=&quot;1. 相关代码&quot;&gt;&lt;/a&gt;1. 相关代码&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;src&amp;#x2F;backend&amp;#x2F;access&amp;#x2F;aocs&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    aocs_compaction.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    aocsam.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    aocssegfiles.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                &amp;#x2F;appendonly&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    appendonlyam.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    aomd.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    aosegfiles.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    appendonly_compaction.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    appendonly_visimap.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    appendonly_visimap_entry.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    appendonly_visimap_store.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    appendonly_visimap_udf.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    appendonlyblockdirectory.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    appendonlytid.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    appendonlywriter.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;src&amp;#x2F;backend&amp;#x2F;utils&amp;#x2F;datumstream&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    datumstream.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                    datumstreamblock.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;src&amp;#x2F;backend&amp;#x2F;cdb&amp;#x2F;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                cdbbufferedappend.c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                cdbbufferedread.c&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="greenplum6.0" scheme="https://zisedeqing.github.io/categories/greenplum6-0/"/>
    
    <category term="aocs" scheme="https://zisedeqing.github.io/categories/greenplum6-0/aocs/"/>
    
    
    <category term="greenplum" scheme="https://zisedeqing.github.io/tags/greenplum/"/>
    
    <category term="aocs" scheme="https://zisedeqing.github.io/tags/aocs/"/>
    
    <category term="列存" scheme="https://zisedeqing.github.io/tags/%E5%88%97%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>Greenplum 6.0 HA</title>
    <link href="https://zisedeqing.github.io/2020/12/28/Greenplum-6-0-HA/"/>
    <id>https://zisedeqing.github.io/2020/12/28/Greenplum-6-0-HA/</id>
    <published>2020-12-28T12:44:34.000Z</published>
    <updated>2020-12-29T01:32:53.318Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-整体架构"><a href="#1-整体架构" class="headerlink" title="1. 整体架构"></a>1. 整体架构</h1><p>Greenplum 6.0 在HA的架构上与4.3基本上一样的，改动比较大的是primary/mirror之间的数据同步机制，由4.3的file replication 改为streaming replication。</p><a id="more"></a><p>整体架构如下：<br><img src="/2020/12/28/Greenplum-6-0-HA/arch.png" alt="整体架构图"><br>Greenplum 集群有一个master和若干个segment组成，master有一个standby做备份，实时同步master上的元数据变更，每个segment都有一个mirror节点，通过流复制实时同步segment上的元信息和数据变更。master/standby和segment的primary/mirror的流复制结构图如下：<br><img src="/2020/12/28/Greenplum-6-0-HA/arch2.png" alt="primary-mirror"><br>在master或者primary节点上，用户backend产生XLOG并修改数据，wal sender进程 读取用户新产生的xlog数据，然后通过流复制协议发送到standby或者mirror节点的wal receiver进程。wal receiver进程接收wal sender发送过来的xlog record，并把xlog record写入xlog 文件，startup进程读取wal sender写入的xlog文件，实时redo产生的xlog record，并把数据变更写入文件。</p><h1 id="2-streaming-replication"><a href="#2-streaming-replication" class="headerlink" title="2. streaming replication"></a>2. streaming replication</h1><p>streaming replication实际上是由2部分组成，一是base backup和流复制协议，base backup是流复制的基本，在primary/master的snapshot上，把增量修改通过流复制协议同步给standby/mirror。</p><h2 id="2-1-base-backup"><a href="#2-1-base-backup" class="headerlink" title="2.1 base backup"></a>2.1 base backup</h2><p>base backup 主要是对primary/segment通过在线的方式对于节点做一个snapshot，以供后续根据该snapshot搭建standby或者PITR(Point-in-Time Recovery)。</p><p>pg提供的机制做base backup的方式如下：</p><ol><li>pg_basebackup 命令行工具</li></ol><p>实际上内部还是通过流复制协议的BASE_BACKUP命令实现的</p><ol start="2"><li>系统内置函数：pg_start_backup，pg_stop_backup</li></ol><p>这种方式目前gp6不支持。</p><ol start="3"><li>通过流复制协议发送BASE_BACKUP命令</li></ol><p>对于内部测试来说，可以通过如下命令执行base backup</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PGOPTIONS=<span class="string">&quot;-c gp_session_role=utility&quot;</span> psql <span class="string">&quot;dbname=postgres replication=database&quot;</span> -c <span class="string">&quot;BASE_BACKUP LABEL &#x27;test_bk&#x27;&quot;</span></span><br></pre></td></tr></table></figure><p>base backup的代码实现主要在perform_base_backup函数内，主要做如下的工作：</p><ol><li>do_pg_start_backup</li></ol><p><img src="/2020/12/28/Greenplum-6-0-HA/do_pg_start_backup.png" alt="do_pg_start_backup"><br>do_pg_start_backup 主要的目的就是要做一次checkpoint，以便后续standby的的redo。</p><ul><li>full page write</li></ul><p>强制做full page write的目的是防止在后面copy 数据的时候读取到未刷完整的page</p><ul><li>switch xlog</li></ul><p>确保checkpoint写入的xlog的timeline id是当前的timeline id。详细的原因可以查看do_pg_start_backup的注释</p><ul><li>create backup label file</li></ul><p>backup label file 不一定会创建，如果是通过流复制协议的BASE_BACKUP命令，就不会创建该文件，但是会把文件的内容发送到client端。backup label file 内容如下：<br><img src="/2020/12/28/Greenplum-6-0-HA/backup-label-file.png" alt="backup label file"></p><ul><li>CHECKPOINT LOCATION</li></ul><p>do_pg_start_backup触发的checkpoint lsn，用于PITR，流复制没有用到该字段</p><ul><li>START WAL LOCATION</li></ul><p>流复制日志的起点位置，在流复制时，wal sender会把该位置之后的xlog 发送给wal receiver。<br>该位置时间上是checkpoint的redo位置，所以也可以理解为，该位置之前的xlog记录的数据库变更都已经flush到磁盘了，因此也就不需要了。</p><ul><li>BACKUP METHOD</li></ul><p>使用何种防止做的base backup：pg_start_backup | streamed<br>对于Greenplum而言，目前应该只有streamed。</p><ul><li>BACKUP FROM</li></ul><p>该backup是对primary 还是 standby做的，这里的primary是postgresql的primary，不是Greenplum的primary segment。<br>对于Greenplum而言，目前应该只有primary。</p><ul><li>START TIME</li></ul><p>backup的时间</p><ul><li>LABEL </li></ul><p>当前backup的label</p><ol start="2"><li>WalSndSetXLogCleanUpTo</li></ol><p>把start wal location更新到wal sender状态里面，该操作的主要目的是防止在wal sender 同步xlog之前，checkpoint回收xlog时，把start wal location之后的xlog给回收掉。<br>对于pg9.4是没有这块代码的，该代码是greenplum 添加的，我找了一下提交记录，在Greenplum 4.3的时候就已经存在了，看来是代码合并的时候直接就把这块代码留下来了。<br>当时Greenplum 4.3添加这块代码的原因是Greenplum 4.3的内核版比较低，master通过流复制与standby同步时，有可能出现还未通过到standby的xlog在master上备回收了。但是在Greenplum 6.0中，可以使用replication slot来解决这个问题，不理解这一块的代码为什么还要保留。</p><ol start="3"><li>send data to client</li></ol><p>把primary/master的数据发送到client端</p><ol start="4"><li>do_pg_stop_backup</li></ol><p><img src="/2020/12/28/Greenplum-6-0-HA/do_pg_stop_backup.png" alt="do_pg_stop_backup"><br>do_pg_stop_backup主要做的事情是把do_pg_start_backup修改的状态重置，并且插入一个backup end xlog，该xlog在standby或者PITR时，用来检查数据一致性</p><ol start="5"><li>if need, send wal file to client</li></ol><h2 id="2-2-streaming-replication"><a href="#2-2-streaming-replication" class="headerlink" title="2.2 streaming replication"></a>2.2 streaming replication</h2><p><img src="/2020/12/28/Greenplum-6-0-HA/streaming-replication.png" alt="streaming replication"><br>上图展示了master/primary与standby/mirror如何通过streaming replication来实现数据同步的：</p><ol><li>master/primary的user backend 执行用户sql，修改数据并产生XLOG，在提交之前backend进程通知wal sender进程把新产生的xlog 同步到 standby/mirror。</li><li>wal sender 进程循环读取xlog file，如果有新的xlog产生，则把xlog 通过流复制协议发送给standby/mirror。</li></ol><p>在发送之前，会先处理standby/mirror发回的replay消息，用于跟踪standby/mirror的xlog write or flush状况。</p><ol start="3"><li>standby/mirror的wal receiver进程收到wal sender进程发送的xlog record后，把xlog record 写入xlog file，并flush到磁盘，然后通知recovery进程，有新的xlog。</li><li>recovery进程循环读取xlog file，如果有新的xlog，则redo。</li></ol><p>streaming replication是master/pirmary产生日志并且flush到xlog 文件之后wal sender才能把xlog 同步到standby/mirror。所以这里还是有一个时间差的，即使在强同步的模式下，如果master/primary在flush xlog后宕掉了，这些flush的xlog是有可能没有同步到standby/mirror上的。</p><h3 id="2-2-1-SyncRepWaitForLSN"><a href="#2-2-1-SyncRepWaitForLSN" class="headerlink" title="2.2.1 SyncRepWaitForLSN"></a>2.2.1 SyncRepWaitForLSN</h3><p>SyncRepWaitForLSN 是用户backend 在事务prepare/commit/abort阶段等待当前事务的xlog全部同步到standby/mirror的接口，该函数调用栈：<br><img src="/2020/12/28/Greenplum-6-0-HA/SyncRepWaitForLSN.png" alt="SyncRepWaitForLSN"><br>SyncRepWaitForLSN函数的主要功能是根据用户配置的同步模式，等待xlog 同步到standby/mirror。</p><ul><li><input checked disabled type="checkbox"> <strong>synchronous_commit</strong></li></ul><p>通过guc参数配置同步级别，级别从低到高：</p><table><thead><tr><th>SYNCHRONOUS_COMMIT_OFF</th><th>异步提交</th></tr></thead><tbody><tr><td>SYNCHRONOUS_COMMIT_LOCAL_FLUSH</td><td>等待本地xlog flush，即primary/master flush xlog</td></tr><tr><td>SYNCHRONOUS_COMMIT_REMOTE_WRITE</td><td>等待standby/mirror write xlog</td></tr><tr><td>SYNCHRONOUS_COMMIT_REMOTE_FLUSH</td><td>等待standby/mirror flush xlog</td></tr></tbody></table><p>默认是SYNCHRONOUS_COMMIT_REMOTE_FLUSH。</p><ul><li><input checked disabled type="checkbox"> <strong>wait 时的中断处理</strong></li></ul><p>有两种中断：</p><ul><li>canceling query    </li></ul><p>对于这个中断，Greenplum 和pg的处理不太一样，pg是抛出WARNING，并取消等待；而gp是直接忽略该中断，继续等待。<br>从代码的注释看，Greenplum这样做的原因是既然用户配置的同步模式，就一定要保证primary 与mirror的同步，而且Greenplum有fts服务，可以自动检测到mirror是否挂掉了，这样gp可以解开因为等待xlog 同步的事务。</p><ul><li>proc die</li></ul><p>如果是master，则抛出WARNING，并取消等待<br>如果是primary，则FATAL当前backend。</p><h3 id="2-2-2-wal-sender"><a href="#2-2-2-wal-sender" class="headerlink" title="2.2.2 wal sender"></a>2.2.2 wal sender</h3><p>wal sender是master/primary上的xlog 发送进程，用于把新产生的xlog 发送到wal receiver端。wal sender 进程的创建是由standby/mirror链接master/primary而创建的，处于测试的目的，可以通如下的命令创建wal sender：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PGOPTIONS=<span class="string">&quot;-c gp_session_role=utility&quot;</span> psql <span class="string">&quot;dbname=postgres replication=database&quot;</span></span><br></pre></td></tr></table></figure><h4 id="2-2-2-1-replication-command"><a href="#2-2-2-1-replication-command" class="headerlink" title="2.2.2.1 replication command"></a>2.2.2.1 replication command</h4><p>wal sender支持多个流复制命令来实现各种功能, 通过上面的psql命令行可以执行这些command：</p><ol><li>identify_system</li></ol><p>返回系统标志，由一下字段组成：<br>systemid | timeline | xlogpos | dbname</p><ol start="2"><li>base_backup</li></ol><p>执行base backup，在上面的章节已经介绍过了。</p><ol start="3"><li>start_replication</li></ol><p>启动物理流复制，即wal sender进程，循环发送xlog。</p><ol start="4"><li>start_logical_replication</li></ol><p>启动逻辑复制流复制，与物理流复制不同的是发送逻辑日志，而不是xlog</p><ol start="5"><li>create_replication_slot</li></ol><p>创建一个replication slot，replication slot会在后面章节介绍</p><ol start="6"><li>drop_replication_slot</li></ol><p>删除replication slot</p><ol start="7"><li>timeline_history</li></ol><p>发送time line history 文件到client端</p><h4 id="2-2-2-2-start-replication"><a href="#2-2-2-2-start-replication" class="headerlink" title="2.2.2.2 start replication"></a>2.2.2.2 start replication</h4><p>start replication 用于启动流复制，command语法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">START_REPLICATION [SLOT slot_name] [PHYSICAL] XXX&#x2F;XXX [TIMELINE tli]</span><br></pre></td></tr></table></figure><ul><li>timeline 表示要复制的xlog的时间线，如果是历史的时间线，则把改时间线内的xlog复制完后，就结束</li><li>startpos xlog复制的起点，一般是base bakcup中返回的start wal location</li><li><input checked disabled type="checkbox"> <strong>wal sender state</strong></li></ul><p>wal sender 通过状态机来工作，状态转换如下：<br><img src="/2020/12/28/Greenplum-6-0-HA/wal-sender-state.png" alt="wal sender state"><br>WALSNDSTATE_STARTUP： 表示wal sender 已经启动，等待输入<br>WALSNDSTATE_BACKUP： 表中wal sender正在做base backup<br>WALSNDSTATE_CATCHUP：表示wal sender正在发送xlog，standby/mirror正在追赶master/primary的xlog<br>WALSNDSTATE_STREAMING：表示standby/mirror与master/primary的xlog处于同步状态。<br>处于该状态的wal sender才可能会成为sync的。当第一次把所有的xlog发送给wal receiver后，从WALSNDSTATE_CATCHUP转换成WALSNDSTATE_STREAMING。</p><p>WALSNDSTATE_STOPPING: wal sender 正在关闭</p><p>可以通过pg_stat_get_wal_senders函数查看wal sender的状态信息。</p><ul><li><input checked disabled type="checkbox"> <strong>wal send main loop</strong></li></ul><p>wal send main loop 流程图如下：<br><img src="/2020/12/28/Greenplum-6-0-HA/wal-send-main-loop.png" alt="wal send main loop"><br>wal sender不断的读取xlog file并发送的wal receiver端，如果没有xlog可读或者上一次的数据还未发送完，则wal sender会处于block状态，唤醒的事件有：WL_LATCH_SET | WL_POSTMASTER_DEATH | WL_TIMEOUT |    WL_SOCKET_READABLE。</p><ul><li><input checked disabled type="checkbox"> <strong>standby/mirror reply</strong></li></ul><p>‘c’ 报文： standby/mirror 结束流复制<br>‘X’ 报文:  standby/mirror socket 关闭<br>‘d’ 报文：状态报文，会把standby/mirror的状态，有2个功能：<br>‘r’:  汇报xlog flush和redo信息，有如下项：<br>xlog writer location<br>xlog flush location<br>xlog redo location<br>wal sender 收到这些信息后，可以根据这些信息唤醒正在等待提交的事务，或者防止xlog被过早的回收（Greenplum不会出现这个问题）<br>‘h’:  hot standby feedback，Greenplum不支持hot standby<br>防止master过早的回收standby可能还需要查询的tuple 版本。<br>这个问题是这样的，vacuum在清理tuple无效版本时，一般是把所有正在运行的事务都不可见的tuple版本清理掉，但是master在做时，只能确定master上所有的事务不可见，但是无法确定tuple版本在standby上是否有事务可见。如果master不理standby而直接把standby上有事务可见的tuple版本清理到，则wal sender把这些更改同步到standby上后，standby的query可能会报错：ERROR: canceling statement due to conflict with recovery。<br>postgresql的解决方案是：hot standby定期汇报自己的oldest xid，master 在清理tuple时，把standby上的事务也考虑在内。</p><h4 id="2-2-2-3-相关系统表"><a href="#2-2-2-3-相关系统表" class="headerlink" title="2.2.2.3 相关系统表"></a>2.2.2.3 相关系统表</h4><ol><li>pg_stat_replication</li></ol><p>postgresql内置系统视图，可以查询单节点上的wal sender状态，如下图所示：<br><img src="/2020/12/28/Greenplum-6-0-HA/pg_stat_replication.png" alt="pg_stat_replication"></p><ol start="2"><li>gp_stat_replication<br>greemplum6.0 内置系统视图，实际上是对pg_stat_replication的封装：</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> gp_stat_get_master_replication() <span class="keyword">RETURNS</span> SETOF RECORD <span class="keyword">AS</span></span><br><span class="line">$$</span><br><span class="line">    <span class="keyword">SELECT</span> pg_catalog.gp_execution_segment() <span class="keyword">AS</span> gp_segment_id, <span class="operator">*</span></span><br><span class="line">    <span class="keyword">FROM</span> pg_catalog.pg_stat_replication</span><br><span class="line">$$</span><br><span class="line"><span class="keyword">LANGUAGE</span> <span class="keyword">SQL</span> <span class="keyword">EXECUTE</span> <span class="keyword">ON</span> MASTER;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> gp_stat_get_segment_replication() <span class="keyword">RETURNS</span> SETOF RECORD <span class="keyword">AS</span></span><br><span class="line">$$</span><br><span class="line">    <span class="keyword">SELECT</span> pg_catalog.gp_execution_segment() <span class="keyword">AS</span> gp_segment_id, <span class="operator">*</span></span><br><span class="line">    <span class="keyword">FROM</span> pg_catalog.pg_stat_replication</span><br><span class="line">$$</span><br><span class="line"><span class="keyword">LANGUAGE</span> <span class="keyword">SQL</span> <span class="keyword">EXECUTE</span> <span class="keyword">ON</span> <span class="keyword">ALL</span> SEGMENTS;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> gp_stat_get_segment_replication_error() <span class="keyword">RETURNS</span> SETOF RECORD <span class="keyword">AS</span></span><br><span class="line">$$</span><br><span class="line">    <span class="keyword">SELECT</span> pg_catalog.gp_execution_segment() <span class="keyword">AS</span> gp_segment_id, pg_catalog.gp_replication_error() <span class="keyword">as</span> sync_error</span><br><span class="line">$$</span><br><span class="line"><span class="keyword">LANGUAGE</span> <span class="keyword">SQL</span> <span class="keyword">EXECUTE</span> <span class="keyword">ON</span> <span class="keyword">ALL</span> SEGMENTS;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> gp_stat_replication <span class="keyword">AS</span></span><br><span class="line">    <span class="keyword">SELECT</span> <span class="operator">*</span>, pg_catalog.gp_replication_error() <span class="keyword">AS</span> sync_error</span><br><span class="line">    <span class="keyword">FROM</span> pg_catalog.gp_stat_get_master_replication() <span class="keyword">AS</span> R</span><br><span class="line">    (gp_segment_id <span class="type">integer</span>, pid <span class="type">integer</span>, usesysid oid,</span><br><span class="line">     usename name, application_name text, client_addr inet, client_hostname text,</span><br><span class="line">     client_port <span class="type">integer</span>, backend_start timestamptz, backend_xmin xid, state text,</span><br><span class="line">     sent_location pg_lsn, write_location pg_lsn, flush_location pg_lsn,</span><br><span class="line">     replay_location pg_lsn, sync_priority <span class="type">integer</span>, sync_state text)</span><br><span class="line">    <span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line">    (</span><br><span class="line">        <span class="keyword">SELECT</span> G.gp_segment_id</span><br><span class="line">            , R.pid, R.usesysid, R.usename, R.application_name, R.client_addr</span><br><span class="line">            , R.client_hostname, R.client_port, R.backend_start, R.backend_xmin, R.state</span><br><span class="line">    , R.sent_location, R.write_location, R.flush_location</span><br><span class="line">    , R.replay_location, R.sync_priority, R.sync_state, G.sync_error</span><br><span class="line">        <span class="keyword">FROM</span> (</span><br><span class="line">            <span class="keyword">SELECT</span> E.<span class="operator">*</span></span><br><span class="line">            <span class="keyword">FROM</span> pg_catalog.gp_segment_configuration C</span><br><span class="line">            <span class="keyword">JOIN</span> pg_catalog.gp_stat_get_segment_replication_error()</span><br><span class="line">    <span class="keyword">AS</span> E (gp_segment_id <span class="type">integer</span>, sync_error text)</span><br><span class="line">            <span class="keyword">ON</span> c.content <span class="operator">=</span> E.gp_segment_id</span><br><span class="line">            <span class="keyword">WHERE</span> C.role <span class="operator">=</span> <span class="string">&#x27;m&#x27;</span></span><br><span class="line">        ) G</span><br><span class="line">        <span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> pg_catalog.gp_stat_get_segment_replication() <span class="keyword">AS</span> R</span><br><span class="line">        (gp_segment_id <span class="type">integer</span>, pid <span class="type">integer</span>, usesysid oid,</span><br><span class="line">         usename name, application_name text, client_addr inet,</span><br><span class="line"> client_hostname text, client_port <span class="type">integer</span>, backend_start timestamptz,</span><br><span class="line"> backend_xmin xid, state text, sent_location pg_lsn,</span><br><span class="line"> write_location pg_lsn, flush_location pg_lsn,</span><br><span class="line">         replay_location pg_lsn, sync_priority <span class="type">integer</span>, sync_state text)</span><br><span class="line">         <span class="keyword">ON</span> G.gp_segment_id <span class="operator">=</span> R.gp_segment_id</span><br><span class="line">    );</span><br></pre></td></tr></table></figure><p>该视图可以在master上执行，收集master和所有segment的replication信息，如下图所示：<br><img src="/2020/12/28/Greenplum-6-0-HA/gp_stat_replication.png" alt="gp_stat_replication"></p><ol start="3"><li>pg_xlog_location_diff</li></ol><p>可以通过如下sql查看mirror/standby 的日志落后了primary/master多少：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">gp_execution_segment() <span class="keyword">as</span> gp_segment_id, </span><br><span class="line">  pg_xlog_location_diff(pg_current_xlog_location(),replay_location)<span class="operator">/</span><span class="number">1024</span><span class="operator">/</span><span class="number">1024</span> <span class="keyword">as</span> MB</span><br><span class="line"><span class="keyword">from</span> gp_dist_random(<span class="string">&#x27;pg_stat_replication&#x27;</span>);</span><br></pre></td></tr></table></figure><h3 id="2-3-2-wal-receiver"><a href="#2-3-2-wal-receiver" class="headerlink" title="2.3.2 wal receiver"></a>2.3.2 wal receiver</h3><p>wal receiver 是standby/mirror的后台进程，在recovery进程redo完现有日志后，会通过RequestXLogStreaming 接口启动wal receiver进程，链接master/primary 启动wal sender进程同步xlog。<br>wal receiver流程图如下：<br><img src="/2020/12/28/Greenplum-6-0-HA/wal-receiver.png" alt="wal receiver"><br>wal receiver 有2层循环，内层循环处理某一个时间线内的xlog的receive，当该时间线内的xlog处理完后，wal sender会停止发送xlog，wal receiver会从master/primary上拉取 最新的timeline history，然后等待startup 进程确定下一个时间线的xlog start location。<br>外层循环处理所有时间线的xlog，每次都会依次发送IDENTIFY_SYSTEM、START_REPLICATION command，从新开始新一个时间线的复制。</p><p>为什么在receive xlog时，会有多个时间线呢？</p><ol><li>cascade replication</li></ol><p>对于级联的standby，如果standby promote为master后，时间线为增加，该standby的standby就需要处理不同时间线的xlog</p><ol start="2"><li>基于比较早的备份做recovery</li></ol><p>如果base backup做的比较早，但是recovery或者以standby启动的时候比较晚，master/standby做过切换后，也会出现这个现象。这个需要master有xlog archive才行，如果没有xlog archive，之前的base backup有可能会找不到需要的xlog。</p><ol start="3"><li>因为bug导致的</li></ol><p>在WaitForWALToBecomeAvailable代码的注释中提到：<br><img src="/2020/12/28/Greenplum-6-0-HA/WaitForWALToBecomeAvailable.png" alt="WaitForWALToBecomeAvailable"></p><h3 id="2-4-2-startup-process"><a href="#2-4-2-startup-process" class="headerlink" title="2.4.2 startup process"></a>2.4.2 startup process</h3><p>startup 进程是standby/mirror上用于xlog replay进程，在standby/mirror启动时，startup进程启动，根据recovery.conf中的配置，确定recovery方式，然后read xlog并redo xlog，如果pg_xlog目录下的xlog都已经redo完，并且standbymode 为on的话，调用RequestXLogStreaming接口启动wal receiver，从master/primary获取xlog，wal receiver收到xlog后，在通知startup 进行redo，如此循环，直到standby promote为master/primary。<br>startup process 主函数为StartupXLOG，该函数无论是用于启动时做xlog replay的主函数。对于postgresql来说只有xlog redo到一致状态后，系统才可以接收服务。对于primary/master，StartupXLOG只是redo pg_xlog目录下面的xlog，对于standby或者其他recovery方式(PITR) 来说值redo pg_xlog 下的日志是不够的。postgresql实现了一个状态机，用来控制xlog的来源，该代码实现在WaitForWALToBecomeAvailable函数内。<br><img src="/2020/12/28/Greenplum-6-0-HA/WaitForWALToBecomeAvailable2.png" alt="WaitForWALToBecomeAvailable state"><br>XLOG_FROM_ANY： 需要的xlog可以是任何来源：archive, pg_xlog,stream,甚至是用户手动copy到pg_xlog下，该状态不参与状态的转换。<br>XLOG_FROM_ARCHIVE：从restore_command从获取xlog<br>XLOG_FROM_PG_XLOG：需要的xlog在pg_xlog目录下<br>XLOG_FROM_STREAM：需要从master/primary 获取xlog</p><h3 id="2-5-2-streaming-replication-protocal"><a href="#2-5-2-streaming-replication-protocal" class="headerlink" title="2.5.2 streaming replication protocal"></a>2.5.2 streaming replication protocal</h3><p>流复制协议，用于实现流复制功能，协议的具体细节可以参考postgresql的官方文档：<a href="https://www.postgresql.org/docs/9.4/protocol-replication.html">https://www.postgresql.org/docs/9.4/protocol-replication.html</a>。<br>如果想要测试流复制写，可以使用psql执行流复制的command，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PGOPTIONS=<span class="string">&quot;-c gp_session_role=utility&quot;</span> psql <span class="string">&quot;dbname=postgres replication=database&quot;</span> -h host -p port</span><br></pre></td></tr></table></figure><h1 id="3-replication-slot"><a href="#3-replication-slot" class="headerlink" title="3. replication slot"></a>3. replication slot</h1><p>replication slot 是postgresql 9.0 引入的一个特性(commit:<a href="https://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=858ec11858a914d4c380971985709b6d6b7dd6fc">https://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=858ec11858a914d4c380971985709b6d6b7dd6fc</a>)，是crash-safe的数据结构，根据功能可分为physical和logical两种，根据生命周期又可分为persistent和ephemeral 两种。ephemeral的replication slot在系统restart或者release时，就会删除。physical replication slot是persistent类型的，logical replication slot是在创建时是ephemeral类型的，创建成功后调用ReplicationSlotPersist修改为persistent类型。</p><p>replication slot 有2种创建方式：</p><ol><li>系统内置函数：pg_create_logical_replication_slot/pg_create_physical_replication_slot、pg_drop_replication_slot</li><li>流复制命令：CREATE_REPLICATION_SLOT/DROP_REPLICATION_SLOT</li></ol><p>可以使用系统内置函数pg_get_replication_slots或者系统视图pg_replication_slots查询所有的replication slots。</p><h2 id="3-1-physical-replication-slot"><a href="#3-1-physical-replication-slot" class="headerlink" title="3.1 physical replication slot"></a>3.1 physical replication slot</h2><p>对于postgresql 而言physical replication slot可以解决流复制时遇到的两个常见问题：</p><ol><li>防止primary上的xlog 过早被回收</li></ol><p>在没有replication slot时，一般是通过wal_keep_segments参数，让primary 保留足够多的xlog，来解决这个问题。<br>physical replication slot解决该问题的方式是：wal sender 收到standby 发送的xlog flush location，然后把改xlog lsn更新到physical replication slot上。CreateCheckPoint在回收xlog时，会check physical replication slot的lsn，把最小的lsn之前的xlog回收掉。</p><ol start="2"><li>与hot_standby_feedback配合使用，防止primary 的vacuum过早的清理到hot standby需要查询的tuple</li></ol><p>wal sender收到wal receiver发送的xmin后，更新到replication slot， primary做vacuum时，会清理min(GetOldestXmin, min(all replication slot feedback xmin) 之前的所有无效版本。</p><p>使用physical replication slot需要注意一下一个问题：</p><ol><li>如果standby长时间未响应，primary replication slot lsn不会更新，会导致primary xlog堆积，有打满磁盘的风险。</li></ol><p>可以通过配置比较小的wal_sender_timeout来解决这个问题。</p><ol start="2"><li>如果hot standby有比较多的慢查询，肯会导致primary vacuum效果很差，无法回收无效的tuple 版本。</li></ol><p>对于greemplum6.0来说，目前physical replication slot的用处不大，因为：</p><ol><li>每个wal sender都会记录standby flush location，checkpoint回收xlog时会检查该lsn，防止过早回收xlog</li></ol><p>gp 加了一个xlogCleanUpTo，来避免xlog过早回收。但是需要注意gp会比较xlogCleanUpTo和replicationSlotMinLSN，选择最小的lsn。所以不要随便创建physical replication slot，不然可能会导致xlog堆积。</p><ol start="2"><li>不支持hot standby，也就不会有vacuum这个问题</li></ol><h2 id="3-2-logical-replication-slot"><a href="#3-2-logical-replication-slot" class="headerlink" title="3.2 logical replication slot"></a>3.2 logical replication slot</h2><p>logical replication slot是用来实现逻辑复制功能的，与physical replication slot的区别就在于physical replication slot 发送的是xlog record，而logical replication slot发送的是逻辑日志。该功能会在下一章的logical decoding详细分析。</p><h1 id="4-logical-decoding"><a href="#4-logical-decoding" class="headerlink" title="4. logical decoding"></a>4. logical decoding</h1><p>logical decoding是postgresql9.4 添加的一个新的功能，可以通过流的方法把数据库的修改通过sql的形式发送消费者。logical replication slot 标识这些修改，并且这些更改只会发送一次。<br>postgresql9.4 版本的logical decoding只支持insert/update/delete 操作，在后面postgresql11时支持了truncate 操作。<br>logical decoding在Greenplum6.0中也是支持的，不过无法对整个集群做，只能对每个segment、master做，可用性比较差。</p><h2 id="4-1-pg-recvlogical"><a href="#4-1-pg-recvlogical" class="headerlink" title="4.1 pg_recvlogical"></a>4.1 pg_recvlogical</h2><p>postgresql官方提供的一个用于接收服务端发送的logical log的工具，简单的用法如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create one new logical replication slot for pg_recvlogical</span></span><br><span class="line">pg_recvlogical --create_slot -S test_slot -d postgres -p 12000</span><br><span class="line"></span><br><span class="line"><span class="comment"># start receive logical log</span></span><br><span class="line">pg_recvlogical --start -S test_slot -d postgres -p 12000 -f -</span><br></pre></td></tr></table></figure><p>pg_recvlogical的输出如下：<br><img src="/2020/12/28/Greenplum-6-0-HA/pg_recvlogical.png" alt="pg_recvlogical"><br>从上图可以看到delete的时候没有解析到删除的行，这个原因是xlog记录的不全导致的，可以通过alter table来修改表在update/delete时对于old tuple的处理方式：<br>DEFAULT：如果有primary key，则记录old tuple的primary key对应的column value， 该方式是user table的默认方式<br>USING INDEX indexname：记录old tuple中indexname key对应的column value<br>FULL：记录old tuple所有的column value<br>NOTHONG：不记录old tuple， system table 的默认方式</p><h2 id="4-2-logical-decoding实现"><a href="#4-2-logical-decoding实现" class="headerlink" title="4.2 logical decoding实现"></a>4.2 logical decoding实现</h2><p>logical decoding 的实现分为下面几个部分：</p><ol><li>logical decoding，负责把数据库的更改，转换成更容易理解的格式，在postgresql中是把wal日志解析成指定的格式。</li><li>replication slot，负责控制数据库change的发送，每个replication slot只能针对单一的数据库。</li><li>output plugin，负责把decode后更改，格式化，该功能已插件的形式提供，用户可以自己编写插件实现不同的输出形式，而不用修改任何数据库内核代码。postgresql官方提供了一个例子：test_decoding</li></ol><p>可以使用START_REPLICATION 指定使用的plugin</p><ol start="4"><li>exported snapshot，在创建logical replication slot时，会自动export一个snapshot，其他session可以import该snapshot，能够看到当时的数据库状态。</li></ol><p>该功能在postgresql9.5时，可以配合pg_dump –snapshot 功能，通过逻辑复制，通过整个database。</p><h2 id="4-3-相关系统函数"><a href="#4-3-相关系统函数" class="headerlink" title="4.3 相关系统函数"></a>4.3 相关系统函数</h2><ol><li>pg_logical_slot_get_changes</li><li>pg_logical_slot_peek_changes</li></ol><h1 id="5-相关tools"><a href="#5-相关tools" class="headerlink" title="5. 相关tools"></a>5. 相关tools</h1><p>postgresql自带的工具</p><ul><li><input checked disabled type="checkbox"> <strong>pg_recvlogical</strong></li></ul><p>用于接收服务器端发送的logical log，使用示例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create one new logical replication slot for pg_recvlogical</span></span><br><span class="line">pg_recvlogical --create_slot -S test_slot -d postgres -p 12000</span><br><span class="line"></span><br><span class="line"><span class="comment"># start receive logical log</span></span><br><span class="line">pg_recvlogical --start -S test_slot -d postgres -p 12000 -f -</span><br></pre></td></tr></table></figure><ul><li><input checked disabled type="checkbox"> <strong>pg_receivexlog</strong></li></ul><p>与pg_recvlogical对应，用于接收服务器端发送的wal log</p><ul><li><input checked disabled type="checkbox"> <strong>pg_basebackup</strong></li></ul><p>用于对数据库创建base backup</p><ul><li><input checked disabled type="checkbox"> <strong>pg_rewind</strong></li></ul><p>用于修改old master data，方便把old master重新加入集群</p><p>greemplum添加的工具：</p><ul><li><input checked disabled type="checkbox"> <strong>gpinitstandby</strong></li></ul><p>为master添加standby节点，执行逻辑为：<br>Updating pg_hba.conf file<br>Do pg_basebackup<br>BASE_BACKUP LABEL ‘pg_basebackup base backup’ PROGRESS WAL FAST NOWAIT  EXCLUDE ‘./db_dumps’EXCLUDE ‘./gpperfmon/data’EXCLUDE ‘./gpperfmon/logs’EXCLUDE ‘./promote’<br>Starting standby master</p><ul><li><input checked disabled type="checkbox"> <strong>gpaddmirrors</strong></li></ul><p>为segment添加mirror节点，与gpinitstandby类似，都是对流复制协议的封装</p><ul><li><input checked disabled type="checkbox"> <strong>gprecoverseg</strong></li></ul><p>recovery 挂掉的segment，使用pg_rewind把旧节点重新加入到集群</p><h1 id="6-fts-fault-tolerance-server"><a href="#6-fts-fault-tolerance-server" class="headerlink" title="6. fts(fault tolerance server)"></a>6. fts(<strong>fault tolerance server)</strong></h1><p>master 监控primary和mirror状态，并在发生故障时，做主备切换。master只会给primary发探活消息，mirror的状态是primary通过wal sender状态来确定，并反馈给master的。</p><p>fts探活协议：<br>FTS_PROBE_SEGMENT<br>FTS_PROBE_SUCCESS<br>primary mirror alive and sync<br>mirror down<br>primary mirror had sync<br>FTS_PROBE_FAILED</p><p>primary:HandleFtsWalRepProbe</p><p>FTS_PROBE_SUCCESS<br>mirror down:FTS_SYNCREP_OFF_SEGMENT</p><p>FTS_SYNCREP_OFF_SEGMENT<br>primary: HandleFtsWalRepSyncRepOff</p><p>FTS_PROBE_FAILED<br>FTS_PROMOTE_SEGMENT</p><p>FTS_PROMOTE_SEGMENT<br>primary:HandleFtsWalRepPromote</p><p>FTS_SYNCREP_OFF_FAILED<br>FTS_PROMOTE_FAILED</p><p>fts相关的几个参数，以及线上默认值：<br>gp_fts_probe_retries：3<br>gp_fts_probe_interval: 30s<br>gp_request_fts_probe_scan<br>gp_fts_probe_timeout: 60s</p><p><strong>最大切换时间: 30 + 3 * (60 + 1) = 213s**<br>*<em>如果不发生timeout是: 30 + 3</em>1 = 33s</strong></p><h1 id="7-与Greenplum-4-3的对比"><a href="#7-与Greenplum-4-3的对比" class="headerlink" title="7. 与Greenplum 4.3的对比"></a>7. 与Greenplum 4.3的对比</h1><p><img src="/2020/12/28/Greenplum-6-0-HA/6.0-4.3-diff.png" alt="6.0与4.3对比"></p><p>Greenplum 4.3 的数据同步分为两种：<br>一是master与standby的同步，使用postgresql原生的streaming replication<br>二是primary与mirror的同步，使用greenplum自己开发的file replication</p><p>而Greenplum 6.0 的数据同步同一使用postgresql原生的streaming replication，这样做有比较多的好处：</p><ol><li>贴近postgresql 社区，后续内核代码合入更容易</li><li>streaming replication架构比replication更简单，而且streaming replication经过postgresql几年的发展更加成熟稳定</li><li>streaming replication比file replication更加的灵活，可以比较容易的实现全量备份+ 增量备份，而且后面还可以实现postgresql的PITR，多standby以及master的host standby等功能</li></ol><h1 id="8-参考资料"><a href="#8-参考资料" class="headerlink" title="8. 参考资料"></a>8. 参考资料</h1><ol><li><a href="http://hlinnaka.iki.fi/presentations/NordicPGDay2015-pg_rewind.pdf">http://hlinnaka.iki.fi/presentations/NordicPGDay2015-pg_rewind.pdf</a></li><li><a href="https://bbs.aliyun.com/read/244478.html">https://bbs.aliyun.com/read/244478.html</a></li><li><a href="https://www.postgresql.org/docs/9.4/protocol-replication.html">https://www.postgresql.org/docs/9.4/protocol-replication.html</a></li><li><a href="https://www.postgresql.org/docs/9.4/logicaldecoding.html">https://www.postgresql.org/docs/9.4/logicaldecoding.html</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;1-整体架构&quot;&gt;&lt;a href=&quot;#1-整体架构&quot; class=&quot;headerlink&quot; title=&quot;1. 整体架构&quot;&gt;&lt;/a&gt;1. 整体架构&lt;/h1&gt;&lt;p&gt;Greenplum 6.0 在HA的架构上与4.3基本上一样的，改动比较大的是primary/mirror之间的数据同步机制，由4.3的file replication 改为streaming replication。&lt;/p&gt;</summary>
    
    
    
    <category term="greenplum6.0" scheme="https://zisedeqing.github.io/categories/greenplum6-0/"/>
    
    <category term="ha" scheme="https://zisedeqing.github.io/categories/greenplum6-0/ha/"/>
    
    
    <category term="greenplum" scheme="https://zisedeqing.github.io/tags/greenplum/"/>
    
    <category term="streaming replication" scheme="https://zisedeqing.github.io/tags/streaming-replication/"/>
    
    <category term="mirror" scheme="https://zisedeqing.github.io/tags/mirror/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://zisedeqing.github.io/2020/12/28/hello-world/"/>
    <id>https://zisedeqing.github.io/2020/12/28/hello-world/</id>
    <published>2020-12-28T08:59:53.742Z</published>
    <updated>2020-12-28T12:26:58.847Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
    <category term="test" scheme="https://zisedeqing.github.io/tags/test/"/>
    
  </entry>
  
</feed>
